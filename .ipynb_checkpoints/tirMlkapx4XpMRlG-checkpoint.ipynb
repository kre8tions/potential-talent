{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62852793",
   "metadata": {},
   "source": [
    "## Potential Talent\n",
    "\n",
    "### **Context:**\n",
    "\n",
    "As a **talent sourcing and management company**, we are interested in **finding talented individuals** for sourcing these candidates to technology companies. **Finding talented candidates is not easy**, for **several reasons**. The **first** reason is one needs to understand what the role is very well to fill in that spot, this requires understanding the client’s needs and what they are looking for in a potential candidate. The **second** reason is one needs to understand what makes a candidate shine for the role we are in search for. **Third**, where to find talented individuals is another challenge.\n",
    "\n",
    "The nature of our job requires a lot of human labor and is full of **manual operations**. Towards **automating this process** we want to build a better approach that could save us time and finally help us spot potential candidates that could fit the roles we are in search for. Moreover, going beyond that for a specific role we want to fill in we are interested in developing a machine learning powered pipeline that could spot talented individuals, and rank them based on their fitness.\n",
    "\n",
    "We are right now semi-automatically sourcing a few candidates, therefore the sourcing part is not a concern at this time but we expect to first determine best matching candidates based on how fit these candidates are for a given role. We generally make these searches based on some keywords such as “full-stack software engineer”, “engineering manager” or “aspiring human resources” based on the role we are trying to fill in. These keywords might change, and you can expect that specific keywords will be provided to you.\n",
    "\n",
    "Assuming that we were able to list and rank fitting candidates, we then employ a review procedure, as each candidate needs to be reviewed and then determined how good a fit they are through manual inspection. This procedure is done manually and at the end of this manual review, we might choose not the first fitting candidate in the list but maybe the 7th candidate in the list. If that happens, we are interested in being able to re-rank the previous list based on this information. This supervisory signal is going to be supplied by starring the 7th candidate in the list. Starring one candidate actually sets this candidate as an ideal candidate for the given role. Then, we expect the list to be re-ranked each time a candidate is starred.\n",
    "\n",
    "### Data Description:\n",
    "\n",
    "The data comes from our sourcing efforts. We removed any field that could directly reveal personal details and gave a unique identifier for each candidate.\n",
    "\n",
    "#### Attributes:\n",
    "**id** : unique identifier for candidate (numeric)\n",
    "\n",
    "**job_title** : job title for candidate (text)\n",
    "\n",
    "**location** : geographical location for candidate (text)\n",
    "\n",
    "**connections** : number of connections candidate has, 500+ means over 500 (text)\n",
    "\n",
    "**Output (desired target)**:\n",
    "fit - how fit the candidate is for the role? (numeric, probability between 0-1)\n",
    "\n",
    "Keywords: “Aspiring human resources” or “seeking human resources”\n",
    "\n",
    "#### Download Data:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/117X6i53dKiO7w6kuA1g1TpdTlv1173h_dPlJt5cNNMU/edit?usp=sharing\n",
    "\n",
    "#### Goal(s):\n",
    "\n",
    "Predict how fit the candidate is based on their available information (variable fit)\n",
    "\n",
    "Success Metric(s):\n",
    "\n",
    "Rank candidates based on a fitness score.\n",
    "\n",
    "Re-rank candidates when a candidate is starred.\n",
    "\n",
    "#### Bonus(es):\n",
    "\n",
    "We are interested in a robust algorithm, tell us how your solution works and show us how your ranking gets better with each starring action.\n",
    "\n",
    "How can we filter out candidates which in the first place should not be in this list?\n",
    "\n",
    "Can we determine a cut-off point that would work for other roles without losing high potential candidates?\n",
    "\n",
    "Do you have any ideas that we should explore so that we can even automate this procedure to prevent human bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e2e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6d8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c013a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272c7de",
   "metadata": {},
   "source": [
    "## Initial Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7419cad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "1   2019 C.T. Bauer College of Business Graduate (...   \n",
       "2   Native English Teacher at EPIK (English Progra...   \n",
       "3               Aspiring Human Resources Professional   \n",
       "4              People Development Coordinator at Ryan   \n",
       "5     Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                               location connection  fit  \n",
       "id                                                       \n",
       "1                        Houston, Texas         85  NaN  \n",
       "2                                Kanada      500+   NaN  \n",
       "3   Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "4                         Denton, Texas      500+   NaN  \n",
       "5                        İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('potential-talents - Aspiring human resources - seeking human resources.csv').set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4e724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 104 entries, 1 to 104\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   job_title   104 non-null    object \n",
      " 1   location    104 non-null    object \n",
      " 2   connection  104 non-null    object \n",
      " 3   fit         0 non-null      float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121f9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('500+ ','501', inplace=True)\n",
    "df['connection'] = pd.to_numeric(df['connection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2135989c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional                 7\n",
       "Aspiring Human Resources Professional                                                                                    7\n",
       "Student at Humber College and Aspiring Human Resources Generalist                                                        7\n",
       "People Development Coordinator at Ryan                                                                                   6\n",
       "Native English Teacher at EPIK (English Program in Korea)                                                                5\n",
       "Aspiring Human Resources Specialist                                                                                      5\n",
       "HR Senior Specialist                                                                                                     5\n",
       "Student at Chapman University                                                                                            4\n",
       "SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR              4\n",
       "Human Resources Coordinator at InterContinental Buckhead Atlanta                                                         4\n",
       "Seeking Human Resources HRIS and Generalist Positions                                                                    4\n",
       "Advisory Board Member at Celal Bayar University                                                                          4\n",
       "Aspiring Human Resources Management student seeking an internship                                                        2\n",
       "Seeking Human Resources Opportunities                                                                                    2\n",
       "Seeking Human  Resources Opportunities. Open to travel and relocation.                                                   1\n",
       "Bachelor of Science in Biology from Victoria University of Wellington                                                    1\n",
       "Human Resources Management Major                                                                                         1\n",
       "Director Human Resources  at EY                                                                                          1\n",
       "Undergraduate Research Assistant at Styczynski Lab                                                                       1\n",
       "Lead Official at Western Illinois University                                                                             1\n",
       "Seeking employment opportunities within Customer Service or Patient Care                                                 1\n",
       "Admissions Representative at Community medical center long beach                                                         1\n",
       "Human Resources Generalist at Loparex                                                                                    1\n",
       "Student at Westfield State University                                                                                    1\n",
       "Student at Indiana University Kokomo - Business Management - \\nRetail Manager at Delphi Hardware and Paint               1\n",
       "Student                                                                                                                  1\n",
       "Seeking Human Resources Position                                                                                         1\n",
       "Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis    1\n",
       "RRP Brand Portfolio Executive at JTI (Japan Tobacco International)                                                       1\n",
       "Business Intelligence and Analytics at Travelers                                                                         1\n",
       "Always set them up for Success                                                                                           1\n",
       "Information Systems Specialist and Programmer with a love for data and organization.                                     1\n",
       "Human Resources Generalist at Schwan's                                                                                   1\n",
       "Human Resources professional for the world leader in GIS software                                                        1\n",
       "Aspiring Human Resources Manager, seeking internship in Human Resources.                                                 1\n",
       "Experienced Retail Manager and aspiring Human Resources Professional                                                     1\n",
       "Human Resources, Staffing and Recruiting Professional                                                                    1\n",
       "Human Resources Specialist at Luxottica                                                                                  1\n",
       "Director of Human Resources North America, Groupe Beneteau                                                               1\n",
       "Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.                           1\n",
       "Human Resources Generalist at ScottMadden, Inc.                                                                          1\n",
       "Business Management Major and Aspiring Human Resources Manager                                                           1\n",
       "Human Resources Professional                                                                                             1\n",
       "HR Manager at Endemol Shine North America                                                                                1\n",
       "Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621                     1\n",
       "Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment    1\n",
       "Human Resources|\\nConflict Management|\\nPolicies & Procedures|Talent Management|Benefits & Compensation                  1\n",
       "Liberal Arts Major. Aspiring Human Resources Analyst.                                                                    1\n",
       "Junior MES Engineer| Information Systems                                                                                 1\n",
       "Senior Human Resources Business Partner at Heil Environmental                                                            1\n",
       "Aspiring Human Resources Professional | An energetic and Team-Focused Leader                                             1\n",
       "Director Of Administration at Excellence Logging                                                                         1\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba0bbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_title.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbd6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0f1cd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53 entries, 1 to 104\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   job_title   53 non-null     object \n",
      " 1   location    53 non-null     object \n",
      " 2   connection  53 non-null     int64  \n",
      " 3   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55ecb1",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb042a",
   "metadata": {},
   "source": [
    "### Prepping our Text for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e190f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40bb1c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b462ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22177a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<1.23.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user \"numpy<1.23.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc517e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385da92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb020407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163e0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Prep our Text for Modelling\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1, 2))\n",
    "docs_tfidf = vectorizer.fit_transform(df[\"job_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbb8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_query_similarity(vectorizer, docs_tfidf, query):\n",
    "    \"\"\"\n",
    "    vectorizer: TfIdfVectorizer model\n",
    "    docs_tfidf: tfidf vectors for all docs\n",
    "    query: query doc\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "    \"\"\"\n",
    "    query_tfidf = vectorizer.transform([query])\n",
    "    cos_sim = cosine_similarity(query_tfidf, docs_tfidf).flatten()\n",
    "    \n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c4d24b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query = 'Aspiring human resources'\n",
    "\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query)\n",
    "\n",
    "df['fit'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f0da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_candidates(n, by = 'fit', ascending = False, min_con = 0, location = df.location):\n",
    "    \n",
    "    df2 = df.loc[(df.connection >= min_con) & (df.location == location)].sort_values(by = by, ascending = ascending).head(n).copy()\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae4c506a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.508880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Business Management Major and Aspiring Human R...</td>\n",
       "      <td>Monroe, Louisiana Area</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.374733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Experienced Retail Manager and aspiring Human ...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>57</td>\n",
       "      <td>0.373847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>0.358949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.340769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Liberal Arts Major. Aspiring Human Resources A...</td>\n",
       "      <td>Baton Rouge, Louisiana Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "3               Aspiring Human Resources Professional   \n",
       "97              Aspiring Human Resources Professional   \n",
       "6                 Aspiring Human Resources Specialist   \n",
       "73  Aspiring Human Resources Manager, seeking inte...   \n",
       "72  Business Management Major and Aspiring Human R...   \n",
       "27  Aspiring Human Resources Management student se...   \n",
       "66  Experienced Retail Manager and aspiring Human ...   \n",
       "7   Student at Humber College and Aspiring Human R...   \n",
       "74                       Human Resources Professional   \n",
       "79  Liberal Arts Major. Aspiring Human Resources A...   \n",
       "\n",
       "                               location  connection       fit  \n",
       "id                                                             \n",
       "3   Raleigh-Durham, North Carolina Area          44  0.735855  \n",
       "97                 Kokomo, Indiana Area          71  0.735855  \n",
       "6            Greater New York City Area           1  0.632697  \n",
       "73                  Houston, Texas Area           7  0.508880  \n",
       "72               Monroe, Louisiana Area           5  0.387590  \n",
       "27                  Houston, Texas Area         501  0.374733  \n",
       "66                   Austin, Texas Area          57  0.373847  \n",
       "7                                Kanada          61  0.358949  \n",
       "74                  Greater Boston Area          16  0.340769  \n",
       "79          Baton Rouge, Louisiana Area           7  0.336485  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e85a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.508880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Business Management Major and Aspiring Human R...</td>\n",
       "      <td>Monroe, Louisiana Area</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.374733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Experienced Retail Manager and aspiring Human ...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>57</td>\n",
       "      <td>0.373847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>0.358949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.340769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Liberal Arts Major. Aspiring Human Resources A...</td>\n",
       "      <td>Baton Rouge, Louisiana Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "3               Aspiring Human Resources Professional   \n",
       "97              Aspiring Human Resources Professional   \n",
       "6                 Aspiring Human Resources Specialist   \n",
       "73  Aspiring Human Resources Manager, seeking inte...   \n",
       "72  Business Management Major and Aspiring Human R...   \n",
       "27  Aspiring Human Resources Management student se...   \n",
       "66  Experienced Retail Manager and aspiring Human ...   \n",
       "7   Student at Humber College and Aspiring Human R...   \n",
       "74                       Human Resources Professional   \n",
       "79  Liberal Arts Major. Aspiring Human Resources A...   \n",
       "\n",
       "                               location  connection       fit  \n",
       "id                                                             \n",
       "3   Raleigh-Durham, North Carolina Area          44  0.735855  \n",
       "97                 Kokomo, Indiana Area          71  0.735855  \n",
       "6            Greater New York City Area           1  0.632697  \n",
       "73                  Houston, Texas Area           7  0.508880  \n",
       "72               Monroe, Louisiana Area           5  0.387590  \n",
       "27                  Houston, Texas Area         501  0.374733  \n",
       "66                   Austin, Texas Area          57  0.373847  \n",
       "7                                Kanada          61  0.358949  \n",
       "74                  Greater Boston Area          16  0.340769  \n",
       "79          Baton Rouge, Louisiana Area           7  0.336485  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4c8c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.374733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Aspiring Human Resources Professional | An ene...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.316420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Aspiring Human Resources Manager | Graduating ...</td>\n",
       "      <td>Cape Girardeau, Missouri</td>\n",
       "      <td>103</td>\n",
       "      <td>0.308829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Aspiring Human Resources Professional | Passio...</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>212</td>\n",
       "      <td>0.246772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.220668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.196509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Human Resources Generalist at Schwan's</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>501</td>\n",
       "      <td>0.196509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Human Resources Generalist at ScottMadden, Inc.</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.196509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.189503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Director Human Resources  at EY</td>\n",
       "      <td>Greater Atlanta Area</td>\n",
       "      <td>349</td>\n",
       "      <td>0.187433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "27   Aspiring Human Resources Management student se...   \n",
       "82   Aspiring Human Resources Professional | An ene...   \n",
       "100  Aspiring Human Resources Manager | Graduating ...   \n",
       "76   Aspiring Human Resources Professional | Passio...   \n",
       "28               Seeking Human Resources Opportunities   \n",
       "101              Human Resources Generalist at Loparex   \n",
       "78              Human Resources Generalist at Schwan's   \n",
       "71     Human Resources Generalist at ScottMadden, Inc.   \n",
       "68             Human Resources Specialist at Luxottica   \n",
       "89                     Director Human Resources  at EY   \n",
       "\n",
       "                                location  connection       fit  \n",
       "id                                                              \n",
       "27                   Houston, Texas Area         501  0.374733  \n",
       "82                    Austin, Texas Area         174  0.316420  \n",
       "100             Cape Girardeau, Missouri         103  0.308829  \n",
       "76                    New York, New York         212  0.246772  \n",
       "28                     Chicago, Illinois         390  0.220668  \n",
       "101  Raleigh-Durham, North Carolina Area         501  0.196509  \n",
       "78           Amerika Birleşik Devletleri         501  0.196509  \n",
       "71   Raleigh-Durham, North Carolina Area         501  0.196509  \n",
       "68            Greater New York City Area         501  0.189503  \n",
       "89                  Greater Atlanta Area         349  0.187433  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'fit', min_con = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac6f372f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Experienced Retail Manager and aspiring Human ...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>57</td>\n",
       "      <td>0.373847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Aspiring Human Resources Professional | An ene...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.316420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title            location  \\\n",
       "id                                                                          \n",
       "66  Experienced Retail Manager and aspiring Human ...  Austin, Texas Area   \n",
       "82  Aspiring Human Resources Professional | An ene...  Austin, Texas Area   \n",
       "\n",
       "    connection       fit  \n",
       "id                        \n",
       "66          57  0.373847  \n",
       "82         174  0.316420  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 50, by = 'fit', location = 'Austin, Texas Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c575ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.189503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Business Intelligence and Analytics at Travelers</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "6                 Aspiring Human Resources Specialist   \n",
       "68            Human Resources Specialist at Luxottica   \n",
       "102  Business Intelligence and Analytics at Travelers   \n",
       "\n",
       "                       location  connection       fit  \n",
       "id                                                     \n",
       "6    Greater New York City Area           1  0.632697  \n",
       "68   Greater New York City Area         501  0.189503  \n",
       "102  Greater New York City Area          49  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 50, by = 'fit', location = 'Greater New York City Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad85a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'seeking human resources'\n",
    "\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query)\n",
    "\n",
    "df['fit'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b8ffe71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.675682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.675682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.432761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Seeking Human  Resources Opportunities. Open t...</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>415</td>\n",
       "      <td>0.381290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.362648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.295223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Nortia Staffing is seeking Human Resources, Pa...</td>\n",
       "      <td>San Jose, California</td>\n",
       "      <td>501</td>\n",
       "      <td>0.273577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.245337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.240319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.240319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "99                   Seeking Human Resources Position   \n",
       "28              Seeking Human Resources Opportunities   \n",
       "10  Seeking Human Resources HRIS and Generalist Po...   \n",
       "94  Seeking Human  Resources Opportunities. Open t...   \n",
       "73  Aspiring Human Resources Manager, seeking inte...   \n",
       "74                       Human Resources Professional   \n",
       "75  Nortia Staffing is seeking Human Resources, Pa...   \n",
       "27  Aspiring Human Resources Management student se...   \n",
       "3               Aspiring Human Resources Professional   \n",
       "97              Aspiring Human Resources Professional   \n",
       "\n",
       "                               location  connection       fit  \n",
       "id                                                             \n",
       "99               Las Vegas, Nevada Area          48  0.675682  \n",
       "28                    Chicago, Illinois         390  0.675682  \n",
       "10            Greater Philadelphia Area         501  0.432761  \n",
       "94          Amerika Birleşik Devletleri         415  0.381290  \n",
       "73                  Houston, Texas Area           7  0.362648  \n",
       "74                  Greater Boston Area          16  0.295223  \n",
       "75                 San Jose, California         501  0.273577  \n",
       "27                  Houston, Texas Area         501  0.245337  \n",
       "3   Raleigh-Durham, North Carolina Area          44  0.240319  \n",
       "97                 Kokomo, Indiana Area          71  0.240319  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa36c8d",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34b208df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "Successfully installed keras-2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you'll have keras 2.15.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl (1.9 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-intel==2.13.1; platform_system == \"Windows\" (from tensorflow) (from versions: 0.0.1, 2.10.0.dev20220728, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0)\n",
      "ERROR: No matching distribution found for tensorflow-intel==2.13.1; platform_system == \"Windows\" (from tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61d53bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alex chung\\anaconda3\\envs\\ml\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "Successfully installed keras-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eee03fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e3089ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dtensor' from 'tensorflow.experimental' (c:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\_api\\v2\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-02ab6e61b6dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TensorFlow version:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dtensor' from 'tensorflow.experimental' (c:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\_api\\v2\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.experimental import dtensor\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f605e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2819ae1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-77d8d067b4a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2da320c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "# !pip install keras\n",
    "# !pip install -U gensim\n",
    "# !pip install tensorflow\n",
    "from tensorflow import keras\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9701abcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "631fe96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2982e",
   "metadata": {},
   "source": [
    "### Prepping our Text for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d74b9db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Alex\n",
      "[nltk_data]     Chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# processing texts for modelling\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "df['job_title_cleaned'] = df.job_title.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() \n",
    "                                                                                  for w in x.split() \n",
    "                                                                                  if re.sub(r'[^a-zA-Z]',' ',w).lower() \n",
    "                                                                                  not in stop_words) ) #nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5376a1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53 entries, 1 to 104\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   job_title          53 non-null     object \n",
      " 1   location           53 non-null     object \n",
      " 2   connection         53 non-null     int64  \n",
      " 3   fit                53 non-null     float64\n",
      " 4   job_title_cleaned  53 non-null     object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d60c574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44746de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (c:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-94fc1f6d9aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tokenize and pad every document to make them of the same size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\applications\\convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtensor_api\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\dtensor\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdtensor_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (c:\\Users\\Alex Chung\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "tokenizer=Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(df.job_title_cleaned)\n",
    "tokenized_documents=tokenizer.texts_to_sequences(df.job_title_cleaned)\n",
    "tokenized_paded_documents=pad_sequences(tokenized_documents,maxlen=64,padding='post')\n",
    "vocab_size=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72658e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading pre-trained embeddings, each word is represented as a 300 dimensional vector\n",
    "import gensim\n",
    "\n",
    "# Navigating to directory where pre-trained embeddings were downloaded\n",
    "os.chdir(r\"C:\\Users\\achung\\OneDrive - Biological Dynamics, Inc\\LX Temp\\Apziva\\Potential Talent\")\n",
    "W2V_PATH=\"GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74884a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1291504e-03, -8.9645386e-04,  3.1852722e-04,  1.5335083e-03,\n",
       "        1.1062622e-03, -1.4038086e-03, -3.0517578e-05, -4.1961670e-04,\n",
       "       -5.7601929e-04,  1.0757446e-03], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)\n",
    "model_w2v[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 64, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "embedding_matrix=np.zeros((vocab_size,300))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if word in model_w2v:\n",
    "        embedding_matrix[i]=model_w2v[word]\n",
    "        \n",
    "# creating document-word embeddings\n",
    "document_word_embeddings=np.zeros((len(tokenized_paded_documents),64,300))\n",
    "for i in range(len(tokenized_paded_documents)):\n",
    "    for j in range(len(tokenized_paded_documents[0])):\n",
    "        document_word_embeddings[i][j]=embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "document_word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1ebd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.08007812e-01,  3.41796875e-02,  2.57568359e-02,  1.79687500e-01,\n",
       "       -1.81640625e-01, -3.41796875e-02, -1.40625000e-01, -1.63085938e-01,\n",
       "       -8.59375000e-02, -1.52343750e-01, -9.57031250e-02, -1.34765625e-01,\n",
       "       -1.92382812e-01,  2.43164062e-01, -1.91406250e-01,  4.93164062e-02,\n",
       "        2.60009766e-02,  3.28125000e-01, -7.37304688e-02,  5.05371094e-02,\n",
       "       -1.52343750e-01, -1.57226562e-01, -1.44958496e-04, -2.51953125e-01,\n",
       "       -4.22363281e-02, -1.72119141e-02, -4.84375000e-01,  2.07031250e-01,\n",
       "       -1.40625000e-01, -1.35498047e-02, -1.78222656e-02,  5.95092773e-03,\n",
       "       -3.10058594e-02, -2.75390625e-01, -2.65625000e-01,  9.52148438e-02,\n",
       "       -4.55078125e-01,  1.13281250e-01, -1.33789062e-01,  1.18652344e-01,\n",
       "       -5.37109375e-02,  8.10546875e-02,  7.32421875e-02,  6.39648438e-02,\n",
       "       -9.47265625e-02,  4.39453125e-02,  1.46484375e-01, -8.59375000e-02,\n",
       "       -1.58203125e-01,  1.63085938e-01, -1.32812500e-01,  2.50000000e-01,\n",
       "       -5.61523438e-02,  2.59765625e-01,  9.52148438e-03,  1.90429688e-01,\n",
       "        3.10058594e-02, -2.47070312e-01, -2.42187500e-01, -2.25585938e-01,\n",
       "       -2.92968750e-02, -1.31835938e-01, -4.14062500e-01, -2.27539062e-01,\n",
       "       -1.06048584e-03, -1.84570312e-01, -5.78613281e-02,  1.97265625e-01,\n",
       "        6.34765625e-03, -1.29882812e-01,  2.13623047e-02, -2.96875000e-01,\n",
       "       -2.26562500e-01, -2.91015625e-01, -6.83593750e-02, -2.53906250e-02,\n",
       "        1.00097656e-01,  6.93359375e-02,  7.76367188e-02, -3.10546875e-01,\n",
       "       -2.07031250e-01, -1.28173828e-02, -5.58471680e-03,  7.66601562e-02,\n",
       "        1.40625000e-01, -9.03320312e-02,  1.36108398e-02,  2.94921875e-01,\n",
       "        9.81445312e-02,  1.01562500e-01,  1.75781250e-01,  1.54296875e-01,\n",
       "       -4.27246094e-02,  5.68847656e-02,  1.67968750e-01,  4.12597656e-02,\n",
       "       -3.99780273e-03,  1.04980469e-01,  1.44531250e-01,  2.84423828e-02,\n",
       "        1.60156250e-01, -2.92968750e-03, -5.12695312e-03, -1.11816406e-01,\n",
       "       -1.04980469e-01,  5.59082031e-02,  3.39355469e-02,  2.17773438e-01,\n",
       "       -1.45263672e-02,  1.90429688e-01, -2.50000000e-01, -6.78710938e-02,\n",
       "       -3.98437500e-01, -7.81250000e-02,  2.86865234e-03,  2.02148438e-01,\n",
       "       -9.13085938e-02, -1.74804688e-01,  1.21582031e-01,  8.20312500e-02,\n",
       "        2.79296875e-01, -1.11328125e-01,  3.78417969e-02,  2.89062500e-01,\n",
       "        1.30859375e-01, -1.56250000e-01,  6.98242188e-02,  3.75000000e-01,\n",
       "        6.22558594e-02,  1.13769531e-01,  4.83398438e-02, -7.56835938e-02,\n",
       "       -3.44238281e-02,  3.49121094e-02, -2.73437500e-01,  3.17382812e-02,\n",
       "       -1.89453125e-01, -9.32617188e-02,  3.78906250e-01, -1.90734863e-03,\n",
       "        3.39843750e-01,  9.52148438e-02,  1.27929688e-01,  1.64794922e-02,\n",
       "       -2.65625000e-01, -3.29589844e-03, -1.27929688e-01,  2.75390625e-01,\n",
       "        4.63867188e-03,  2.79296875e-01,  3.61328125e-02, -3.65234375e-01,\n",
       "       -2.75390625e-01,  2.39257812e-01,  8.88671875e-02,  6.15234375e-02,\n",
       "        1.22558594e-01,  1.17187500e-01, -6.17675781e-02, -1.25732422e-02,\n",
       "        8.78906250e-02,  2.92968750e-01,  1.80664062e-01, -7.91015625e-02,\n",
       "       -8.64257812e-02, -1.40625000e-01,  1.85546875e-01,  1.32812500e-01,\n",
       "       -9.66796875e-02,  5.66406250e-02, -4.48608398e-03, -3.84765625e-01,\n",
       "       -8.78906250e-02, -2.28515625e-01, -1.01074219e-01,  4.41406250e-01,\n",
       "        3.33984375e-01, -3.53515625e-01,  2.13623047e-02, -7.47070312e-02,\n",
       "       -3.47656250e-01, -8.93554688e-02,  1.91406250e-01, -8.30078125e-02,\n",
       "       -1.75781250e-01,  2.43164062e-01, -2.09960938e-02,  5.78613281e-02,\n",
       "       -3.32031250e-02, -9.38415527e-04,  3.79943848e-03, -3.36914062e-02,\n",
       "       -2.53906250e-01,  8.59375000e-02,  1.36718750e-01,  1.58203125e-01,\n",
       "       -6.49414062e-02, -6.93359375e-02,  3.20312500e-01, -8.98437500e-02,\n",
       "        9.57031250e-02,  2.85644531e-02, -3.39843750e-01, -2.63671875e-01,\n",
       "       -4.95605469e-02,  1.78527832e-03, -1.30859375e-01,  1.39648438e-01,\n",
       "        1.07910156e-01,  1.25976562e-01,  5.10253906e-02, -1.00585938e-01,\n",
       "        1.19140625e-01,  1.68945312e-01, -7.61718750e-02,  1.72851562e-01,\n",
       "       -8.15429688e-02,  2.59765625e-01,  6.93359375e-02, -1.05468750e-01,\n",
       "        1.62353516e-02,  2.51953125e-01,  3.49609375e-01, -1.67968750e-01,\n",
       "        2.40234375e-01,  2.59765625e-01,  7.56835938e-02,  7.37304688e-02,\n",
       "        1.39648438e-01, -1.81640625e-01, -1.36718750e-01,  6.89697266e-03,\n",
       "       -3.80859375e-02,  3.73840332e-03, -1.69921875e-01,  1.53320312e-01,\n",
       "        3.82812500e-01,  1.84326172e-02,  1.73828125e-01, -8.69140625e-02,\n",
       "        1.50390625e-01,  4.37500000e-01,  2.21679688e-01,  9.47265625e-02,\n",
       "       -1.06933594e-01,  2.92968750e-01, -1.15234375e-01,  2.08007812e-01,\n",
       "       -4.19921875e-02, -1.77734375e-01,  3.61328125e-01, -6.20117188e-02,\n",
       "        6.59179688e-02, -2.28515625e-01,  1.05957031e-01, -1.22558594e-01,\n",
       "       -1.11328125e-01,  1.91650391e-02,  6.54296875e-02, -2.20947266e-02,\n",
       "       -2.03125000e-01,  2.49862671e-04,  9.03320312e-02,  1.84570312e-01,\n",
       "       -3.24218750e-01,  1.03515625e-01,  2.59765625e-01,  9.58251953e-03,\n",
       "        1.51977539e-02, -2.59765625e-01, -6.31713867e-03, -4.68750000e-02,\n",
       "        1.93359375e-01, -1.22680664e-02, -2.00195312e-01, -2.96875000e-01,\n",
       "       -2.57812500e-01, -1.22558594e-01, -7.51953125e-02,  2.67578125e-01,\n",
       "       -9.27734375e-03,  4.92187500e-01, -1.17187500e-01,  7.76367188e-02,\n",
       "        4.90722656e-02,  2.77343750e-01,  6.64062500e-02, -2.67333984e-02,\n",
       "       -5.51757812e-02, -1.39648438e-01,  1.60156250e-01, -1.01562500e-01,\n",
       "       -9.66796875e-02,  9.47265625e-02,  8.44726562e-02, -2.37304688e-01,\n",
       "       -6.73828125e-02,  9.57031250e-02, -4.68750000e-02,  2.37304688e-01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ae431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_similarity = np.dot(model_w2v['spain'], model_w2v['england'])/(np.linalg.norm(model_w2v['spain'])* \n",
    "#                                                                       np.linalg.norm(model_w2v['england']))\n",
    "# cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27058ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3671875 , -0.03491211,  0.11083984,  0.40039062,  0.18261719],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['england'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794d886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processing(query):\n",
    "    df3 = pd.DataFrame([query], columns=['query'])\n",
    "    stop_words = stopwords.words('english')\n",
    "    df3['processed'] = df3['query'].apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() \n",
    "                                                                                  for w in x.split() \n",
    "                                                                                  if re.sub(r'[^a-zA-Z]',' ',w).lower() \n",
    "                                                                                  not in stop_words) )\n",
    "    \n",
    "    tokenizer.fit_on_texts(df3.processed)\n",
    "    tokenized_documents=tokenizer.texts_to_sequences(df3.processed)\n",
    "    tokenized_paded_documents=pad_sequences(tokenized_documents,maxlen=64,padding='post')\n",
    "    vocab_size=len(tokenizer.word_index)+1\n",
    "    \n",
    "    embedding_matrix=np.zeros((vocab_size,300))\n",
    "    for word,i in tokenizer.word_index.items():\n",
    "        if word in model_w2v:\n",
    "            embedding_matrix[i]=model_w2v[word]\n",
    "\n",
    "    # creating document-word embeddings\n",
    "    query_document_word_embeddings=np.zeros((len(tokenized_paded_documents),64,300))\n",
    "    for i in range(len(tokenized_paded_documents)):\n",
    "        for j in range(len(tokenized_paded_documents[0])):\n",
    "            query_document_word_embeddings[i][j]=embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "#     document_word_embeddings.shape\n",
    "    \n",
    "    return query_document_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31049804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing('hello world!!!!').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155db2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n",
       "       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n",
       "       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n",
       "        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing('hello world!!!!')[0][:3][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_query_similarity(document_word_embeddings, query):\n",
    "    \"\"\"\n",
    "    query_w2v: processing the query\n",
    "    model_w2v: word2vec embedding for all docs\n",
    "    query: query doc\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "\n",
    "    \"\"\"\n",
    "    query_w2v = processing(query)\n",
    "    \n",
    "    nsamples, nx, ny = query_w2v.shape\n",
    "    query_w2v_reshape = query_w2v.reshape((nsamples,nx*ny))\n",
    "\n",
    "    nsamples, nx, ny = document_word_embeddings.shape\n",
    "    document_word_embeddings_reshape = document_word_embeddings.reshape((nsamples,nx*ny))\n",
    "    \n",
    "    cos_sim_w2v = cosine_similarity(query_w2v_reshape, document_word_embeddings_reshape).flatten()\n",
    "    \n",
    "    return cos_sim_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Aspiring human resources'\n",
    "\n",
    "# Word2Vec Similarity\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v\n",
    "\n",
    "# Original TFIDF similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim\n",
    "# Dropping the original fit column\n",
    "# df.drop('fit', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4ffe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.632697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.654387</td>\n",
       "      <td>0.220668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Aspiring Human Resources Professional | An ene...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>aspiring human resources professional   energe...</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.316420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.245337</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>0.628601</td>\n",
       "      <td>0.374733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.619797</td>\n",
       "      <td>0.220668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>aspiring human resources manager  seeking inte...</td>\n",
       "      <td>0.584569</td>\n",
       "      <td>0.508880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Aspiring Human Resources Professional | Passio...</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>212</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>aspiring human resources professional   passio...</td>\n",
       "      <td>0.551164</td>\n",
       "      <td>0.246772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.432761</td>\n",
       "      <td>seeking human resources hris generalist positions</td>\n",
       "      <td>0.519345</td>\n",
       "      <td>0.141333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "97              Aspiring Human Resources Professional   \n",
       "3               Aspiring Human Resources Professional   \n",
       "6                 Aspiring Human Resources Specialist   \n",
       "99                   Seeking Human Resources Position   \n",
       "82  Aspiring Human Resources Professional | An ene...   \n",
       "27  Aspiring Human Resources Management student se...   \n",
       "28              Seeking Human Resources Opportunities   \n",
       "73  Aspiring Human Resources Manager, seeking inte...   \n",
       "76  Aspiring Human Resources Professional | Passio...   \n",
       "10  Seeking Human Resources HRIS and Generalist Po...   \n",
       "\n",
       "                               location  connection       fit  \\\n",
       "id                                                              \n",
       "97                 Kokomo, Indiana Area          71  0.240319   \n",
       "3   Raleigh-Durham, North Carolina Area          44  0.240319   \n",
       "6            Greater New York City Area           1  0.206629   \n",
       "99               Las Vegas, Nevada Area          48  0.675682   \n",
       "82                   Austin, Texas Area         174  0.103338   \n",
       "27                  Houston, Texas Area         501  0.245337   \n",
       "28                    Chicago, Illinois         390  0.675682   \n",
       "73                  Houston, Texas Area           7  0.362648   \n",
       "76                   New York, New York         212  0.080592   \n",
       "10            Greater Philadelphia Area         501  0.432761   \n",
       "\n",
       "                                    job_title_cleaned   w2v_fit  tfidf_fit  \n",
       "id                                                                          \n",
       "97              aspiring human resources professional  0.898174   0.735855  \n",
       "3               aspiring human resources professional  0.898174   0.735855  \n",
       "6                 aspiring human resources specialist  0.873679   0.632697  \n",
       "99                   seeking human resources position  0.654387   0.220668  \n",
       "82  aspiring human resources professional   energe...  0.641739   0.316420  \n",
       "27  aspiring human resources management student se...  0.628601   0.374733  \n",
       "28              seeking human resources opportunities  0.619797   0.220668  \n",
       "73  aspiring human resources manager  seeking inte...  0.584569   0.508880  \n",
       "76  aspiring human resources professional   passio...  0.551164   0.246772  \n",
       "10  seeking human resources hris generalist positions  0.519345   0.141333  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'w2v_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290787a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'seeking human resources'\n",
    "\n",
    "# Word2Vec Similarity\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v\n",
    "\n",
    "# Original TFIDF similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b286dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.886226</td>\n",
       "      <td>0.675682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.839381</td>\n",
       "      <td>0.675682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.432761</td>\n",
       "      <td>seeking human resources hris generalist positions</td>\n",
       "      <td>0.703341</td>\n",
       "      <td>0.432761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.206629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Seeking Human  Resources Opportunities. Open t...</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>415</td>\n",
       "      <td>0.381290</td>\n",
       "      <td>seeking human resources opportunities  open tr...</td>\n",
       "      <td>0.639099</td>\n",
       "      <td>0.381290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Director Human Resources  at EY</td>\n",
       "      <td>Greater Atlanta Area</td>\n",
       "      <td>349</td>\n",
       "      <td>0.162381</td>\n",
       "      <td>director human resources ey</td>\n",
       "      <td>0.571728</td>\n",
       "      <td>0.162381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Aspiring Human Resources Professional | An ene...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>aspiring human resources professional   energe...</td>\n",
       "      <td>0.473859</td>\n",
       "      <td>0.103338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Senior Human Resources Business Partner at Hei...</td>\n",
       "      <td>Chattanooga, Tennessee Area</td>\n",
       "      <td>455</td>\n",
       "      <td>0.102581</td>\n",
       "      <td>senior human resources business partner heil e...</td>\n",
       "      <td>0.470671</td>\n",
       "      <td>0.102581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "99                   Seeking Human Resources Position   \n",
       "28              Seeking Human Resources Opportunities   \n",
       "10  Seeking Human Resources HRIS and Generalist Po...   \n",
       "97              Aspiring Human Resources Professional   \n",
       "3               Aspiring Human Resources Professional   \n",
       "6                 Aspiring Human Resources Specialist   \n",
       "94  Seeking Human  Resources Opportunities. Open t...   \n",
       "89                    Director Human Resources  at EY   \n",
       "82  Aspiring Human Resources Professional | An ene...   \n",
       "81  Senior Human Resources Business Partner at Hei...   \n",
       "\n",
       "                               location  connection       fit  \\\n",
       "id                                                              \n",
       "99               Las Vegas, Nevada Area          48  0.675682   \n",
       "28                    Chicago, Illinois         390  0.675682   \n",
       "10            Greater Philadelphia Area         501  0.432761   \n",
       "97                 Kokomo, Indiana Area          71  0.240319   \n",
       "3   Raleigh-Durham, North Carolina Area          44  0.240319   \n",
       "6            Greater New York City Area           1  0.206629   \n",
       "94          Amerika Birleşik Devletleri         415  0.381290   \n",
       "89                 Greater Atlanta Area         349  0.162381   \n",
       "82                   Austin, Texas Area         174  0.103338   \n",
       "81          Chattanooga, Tennessee Area         455  0.102581   \n",
       "\n",
       "                                    job_title_cleaned   w2v_fit  tfidf_fit  \n",
       "id                                                                          \n",
       "99                   seeking human resources position  0.886226   0.675682  \n",
       "28              seeking human resources opportunities  0.839381   0.675682  \n",
       "10  seeking human resources hris generalist positions  0.703341   0.432761  \n",
       "97              aspiring human resources professional  0.663209   0.240319  \n",
       "3               aspiring human resources professional  0.663209   0.240319  \n",
       "6                 aspiring human resources specialist  0.645122   0.206629  \n",
       "94  seeking human resources opportunities  open tr...  0.639099   0.381290  \n",
       "89                        director human resources ey  0.571728   0.162381  \n",
       "82  aspiring human resources professional   energe...  0.473859   0.103338  \n",
       "81  senior human resources business partner heil e...  0.470671   0.102581  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'w2v_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'business intelligence specialist'\n",
    "\n",
    "# Word2Vec Similarity\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v\n",
    "\n",
    "# Original TFIDF similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34843b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Business Intelligence and Analytics at Travelers</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>business intelligence analytics travelers</td>\n",
       "      <td>0.552532</td>\n",
       "      <td>0.560060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>human resources specialist luxottica</td>\n",
       "      <td>0.447380</td>\n",
       "      <td>0.178214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>hr senior specialist</td>\n",
       "      <td>0.348536</td>\n",
       "      <td>0.168359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Information Systems Specialist and Programmer ...</td>\n",
       "      <td>Gaithersburg, Maryland</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>information systems specialist programmer love...</td>\n",
       "      <td>0.274835</td>\n",
       "      <td>0.099972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>human resources generalist loparex</td>\n",
       "      <td>0.251939</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Human Resources Generalist at Schwan's</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>501</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>human resources generalist schwan s</td>\n",
       "      <td>0.231181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human Resources Coordinator at InterContinenta...</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "      <td>501</td>\n",
       "      <td>0.111899</td>\n",
       "      <td>human resources coordinator intercontinental b...</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Business Management Major and Aspiring Human R...</td>\n",
       "      <td>Monroe, Louisiana Area</td>\n",
       "      <td>5</td>\n",
       "      <td>0.126581</td>\n",
       "      <td>business management major aspiring human resou...</td>\n",
       "      <td>0.214225</td>\n",
       "      <td>0.122980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>0.205907</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Human Resources Generalist at ScottMadden, Inc.</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>human resources generalist scottmadden  inc</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "102   Business Intelligence and Analytics at Travelers   \n",
       "68             Human Resources Specialist at Luxottica   \n",
       "8                                 HR Senior Specialist   \n",
       "86   Information Systems Specialist and Programmer ...   \n",
       "101              Human Resources Generalist at Loparex   \n",
       "78              Human Resources Generalist at Schwan's   \n",
       "13   Human Resources Coordinator at InterContinenta...   \n",
       "72   Business Management Major and Aspiring Human R...   \n",
       "4               People Development Coordinator at Ryan   \n",
       "71     Human Resources Generalist at ScottMadden, Inc.   \n",
       "\n",
       "                                location  connection       fit  \\\n",
       "id                                                               \n",
       "102           Greater New York City Area          49  0.000000   \n",
       "68            Greater New York City Area         501  0.164174   \n",
       "8                 San Francisco Bay Area         501  0.000000   \n",
       "86                Gaithersburg, Maryland           4  0.000000   \n",
       "101  Raleigh-Durham, North Carolina Area         501  0.170244   \n",
       "78           Amerika Birleşik Devletleri         501  0.170244   \n",
       "13                      Atlanta, Georgia         501  0.111899   \n",
       "72                Monroe, Louisiana Area           5  0.126581   \n",
       "4                          Denton, Texas         501  0.000000   \n",
       "71   Raleigh-Durham, North Carolina Area         501  0.170244   \n",
       "\n",
       "                                     job_title_cleaned   w2v_fit  tfidf_fit  \n",
       "id                                                                           \n",
       "102          business intelligence analytics travelers  0.552532   0.560060  \n",
       "68                human resources specialist luxottica  0.447380   0.178214  \n",
       "8                                 hr senior specialist  0.348536   0.168359  \n",
       "86   information systems specialist programmer love...  0.274835   0.099972  \n",
       "101                 human resources generalist loparex  0.251939   0.000000  \n",
       "78                 human resources generalist schwan s  0.231181   0.000000  \n",
       "13   human resources coordinator intercontinental b...  0.215800   0.000000  \n",
       "72   business management major aspiring human resou...  0.214225   0.122980  \n",
       "4                  people development coordinator ryan  0.205907   0.000000  \n",
       "71        human resources generalist scottmadden  inc   0.202920   0.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'w2v_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ea13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Business Intelligence and Analytics at Travelers</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>business intelligence analytics travelers</td>\n",
       "      <td>0.552532</td>\n",
       "      <td>0.560060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>human resources specialist luxottica</td>\n",
       "      <td>0.447380</td>\n",
       "      <td>0.178214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "102  Business Intelligence and Analytics at Travelers   \n",
       "68            Human Resources Specialist at Luxottica   \n",
       "\n",
       "                       location  connection       fit  \\\n",
       "id                                                      \n",
       "102  Greater New York City Area          49  0.000000   \n",
       "68   Greater New York City Area         501  0.164174   \n",
       "\n",
       "                             job_title_cleaned   w2v_fit  tfidf_fit  \n",
       "id                                                                   \n",
       "102  business intelligence analytics travelers  0.552532   0.560060  \n",
       "68        human resources specialist luxottica  0.447380   0.178214  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'w2v_fit', ascending = False, min_con = 20, location = 'Greater New York City Area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd756c",
   "metadata": {},
   "source": [
    "# GloVe - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76257b",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65758f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=a9df2cc2c098f18fdcec6c65d385fa46720171bf24a2369b0f862cc6739b9c3c\n",
      "  Stored in directory: c:\\users\\achung\\appdata\\local\\pip\\cache\\wheels\\8b\\f1\\7f\\5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'glove.840B.300d.zip'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading GloVe pre-trained vectors\n",
    "# !pip install wget\n",
    "# import wget\n",
    "# wget.download('https://nlp.stanford.edu/data/glove.840B.300d.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting GloVe vector file\n",
    "# import zipfile as zf\n",
    "# files = zf.ZipFile(\"glove.840B.300d.zip\", 'r')\n",
    "# files.extractall('GloVe')\n",
    "# files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea67983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating to directory where GloVe pre-trained vectors were downloaded\n",
    "os.chdir(r\"C:\\Users\\achung\\OneDrive - Biological Dynamics, Inc\\LX Temp\\Apziva\\Potential Talent\\GloVe\")\n",
    "path = 'glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccde25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", -0.082752 0.67204 -0.14987 -0.064983 0.056491 0.40228 0.0027747 -0.3311 -0.30691 2.0817 0.031819 0\n",
      ". 0.012001 0.20751 -0.12578 -0.59325 0.12525 0.15975 0.13748 -0.33157 -0.13694 1.7893 -0.47094 0.704\n",
      "the 0.27204 -0.06203 -0.1884 0.023225 -0.018158 0.0067192 -0.13877 0.17708 0.17709 2.5882 -0.35179 -\n",
      "and -0.18567 0.066008 -0.25209 -0.11725 0.26513 0.064908 0.12291 -0.093979 0.024321 2.4926 -0.017916\n",
      "to 0.31924 0.06316 -0.27858 0.2612 0.079248 -0.21462 -0.10495 0.15495 -0.03353 2.4834 -0.50904 0.087\n",
      "of 0.060216 0.21799 -0.04249 -0.38618 -0.15388 0.034635 0.22243 0.21718 0.0068483 2.4375 -0.27418 0.\n",
      "a 0.043798 0.024779 -0.20937 0.49745 0.36019 -0.37503 -0.052078 -0.60555 0.036744 2.2085 -0.23389 -0\n",
      "in 0.089187 0.25792 0.26282 -0.029365 0.47187 -0.10389 -0.10013 0.08123 0.20883 2.5726 -0.67854 0.03\n",
      "\" -0.075242 0.57337 -0.31908 -0.18484 0.88867 -0.27381 0.077588 0.13905 -0.47746 1.4442 -0.56159 0.0\n",
      ": 0.008746 0.33214 -0.29175 -0.15119 -0.41842 -0.23931 -0.23458 -0.055618 -0.09896 0.75175 -0.66615 \n"
     ]
    }
   ],
   "source": [
    "with open(path) as file:\n",
    "  for i in range(10):\n",
    "    line = file.readline()\n",
    "    print(line[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7520de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>\"</th>\n",
       "      <th>:</th>\n",
       "      <th>is</th>\n",
       "      <th>for</th>\n",
       "      <th>I</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>...</th>\n",
       "      <th>what-might-have-been</th>\n",
       "      <th>wiid</th>\n",
       "      <th>windowsTransgender</th>\n",
       "      <th>woombie</th>\n",
       "      <th>wordsforyoungmen</th>\n",
       "      <th>work.Like</th>\n",
       "      <th>working.So</th>\n",
       "      <th>wried</th>\n",
       "      <th>wwent</th>\n",
       "      <th>xalisae</th>\n",
       "      <th>xtremecaffeine</th>\n",
       "      <th>yildirim</th>\n",
       "      <th>z/28</th>\n",
       "      <th>zipout</th>\n",
       "      <th>zulchzulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.082752</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.272040</td>\n",
       "      <td>-0.185670</td>\n",
       "      <td>0.319240</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.043798</td>\n",
       "      <td>0.089187</td>\n",
       "      <td>-0.075242</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>-0.084961</td>\n",
       "      <td>-0.172240</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>-0.271420</td>\n",
       "      <td>-0.180240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562950</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>-0.102350</td>\n",
       "      <td>0.65711</td>\n",
       "      <td>-0.378200</td>\n",
       "      <td>-0.23822</td>\n",
       "      <td>0.754650</td>\n",
       "      <td>0.54698</td>\n",
       "      <td>0.921790</td>\n",
       "      <td>0.337540</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>0.222760</td>\n",
       "      <td>0.73440</td>\n",
       "      <td>0.21215</td>\n",
       "      <td>-0.079690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.672040</td>\n",
       "      <td>0.207510</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>0.066008</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0.217990</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>0.257920</td>\n",
       "      <td>0.573370</td>\n",
       "      <td>0.332140</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.182340</td>\n",
       "      <td>0.226030</td>\n",
       "      <td>0.047374</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293780</td>\n",
       "      <td>-0.315230</td>\n",
       "      <td>-0.043862</td>\n",
       "      <td>-1.06710</td>\n",
       "      <td>-1.154600</td>\n",
       "      <td>-0.65700</td>\n",
       "      <td>-0.292360</td>\n",
       "      <td>-0.50515</td>\n",
       "      <td>-0.344320</td>\n",
       "      <td>-0.131110</td>\n",
       "      <td>-1.029400</td>\n",
       "      <td>-0.296390</td>\n",
       "      <td>-0.33641</td>\n",
       "      <td>-0.99456</td>\n",
       "      <td>-0.229050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.149870</td>\n",
       "      <td>-0.125780</td>\n",
       "      <td>-0.188400</td>\n",
       "      <td>-0.252090</td>\n",
       "      <td>-0.278580</td>\n",
       "      <td>-0.042490</td>\n",
       "      <td>-0.209370</td>\n",
       "      <td>0.262820</td>\n",
       "      <td>-0.319080</td>\n",
       "      <td>-0.291750</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>-0.278470</td>\n",
       "      <td>-0.437640</td>\n",
       "      <td>-0.172780</td>\n",
       "      <td>-0.304630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>-0.103690</td>\n",
       "      <td>0.193270</td>\n",
       "      <td>-0.27787</td>\n",
       "      <td>0.387420</td>\n",
       "      <td>-0.18234</td>\n",
       "      <td>-0.211210</td>\n",
       "      <td>0.56164</td>\n",
       "      <td>-0.508880</td>\n",
       "      <td>0.155950</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>0.694120</td>\n",
       "      <td>0.26918</td>\n",
       "      <td>1.17820</td>\n",
       "      <td>0.803660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.064983</td>\n",
       "      <td>-0.593250</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>-0.386180</td>\n",
       "      <td>0.497450</td>\n",
       "      <td>-0.029365</td>\n",
       "      <td>-0.184840</td>\n",
       "      <td>-0.151190</td>\n",
       "      <td>-0.167550</td>\n",
       "      <td>-0.084666</td>\n",
       "      <td>-0.113870</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>0.209970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070849</td>\n",
       "      <td>-0.110770</td>\n",
       "      <td>-0.225560</td>\n",
       "      <td>0.48507</td>\n",
       "      <td>1.288100</td>\n",
       "      <td>-0.27082</td>\n",
       "      <td>-0.105820</td>\n",
       "      <td>-0.29412</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-1.124400</td>\n",
       "      <td>0.726150</td>\n",
       "      <td>0.193620</td>\n",
       "      <td>0.41843</td>\n",
       "      <td>2.07210</td>\n",
       "      <td>-0.788650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056491</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>-0.153880</td>\n",
       "      <td>0.360190</td>\n",
       "      <td>0.471870</td>\n",
       "      <td>0.888670</td>\n",
       "      <td>-0.418420</td>\n",
       "      <td>0.307210</td>\n",
       "      <td>0.254420</td>\n",
       "      <td>-0.072725</td>\n",
       "      <td>-0.219100</td>\n",
       "      <td>0.085153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487520</td>\n",
       "      <td>0.172950</td>\n",
       "      <td>-0.148480</td>\n",
       "      <td>-0.51166</td>\n",
       "      <td>-0.802670</td>\n",
       "      <td>0.37388</td>\n",
       "      <td>-0.295270</td>\n",
       "      <td>-0.35497</td>\n",
       "      <td>-0.151450</td>\n",
       "      <td>0.100460</td>\n",
       "      <td>-0.992460</td>\n",
       "      <td>-0.312760</td>\n",
       "      <td>-0.18900</td>\n",
       "      <td>-0.44271</td>\n",
       "      <td>-0.405670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.053380</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>-0.039709</td>\n",
       "      <td>-0.258100</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.080421</td>\n",
       "      <td>0.193680</td>\n",
       "      <td>-0.212800</td>\n",
       "      <td>0.700590</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>-0.122380</td>\n",
       "      <td>-0.036109</td>\n",
       "      <td>0.066062</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080746</td>\n",
       "      <td>0.092665</td>\n",
       "      <td>-0.223050</td>\n",
       "      <td>-0.43677</td>\n",
       "      <td>0.503820</td>\n",
       "      <td>0.28653</td>\n",
       "      <td>-0.484500</td>\n",
       "      <td>-0.21834</td>\n",
       "      <td>-0.406440</td>\n",
       "      <td>-0.094080</td>\n",
       "      <td>0.127380</td>\n",
       "      <td>-0.413980</td>\n",
       "      <td>-0.48432</td>\n",
       "      <td>-0.41382</td>\n",
       "      <td>-0.205220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.050821</td>\n",
       "      <td>0.140190</td>\n",
       "      <td>0.114070</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>-0.044629</td>\n",
       "      <td>-0.175970</td>\n",
       "      <td>-0.061246</td>\n",
       "      <td>-0.325460</td>\n",
       "      <td>-0.226150</td>\n",
       "      <td>-0.213710</td>\n",
       "      <td>-0.067180</td>\n",
       "      <td>-0.081083</td>\n",
       "      <td>0.112210</td>\n",
       "      <td>-0.241770</td>\n",
       "      <td>-0.235960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571630</td>\n",
       "      <td>-0.087504</td>\n",
       "      <td>0.161510</td>\n",
       "      <td>-0.43438</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>-0.83764</td>\n",
       "      <td>-0.343440</td>\n",
       "      <td>0.44104</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>-0.361960</td>\n",
       "      <td>0.129570</td>\n",
       "      <td>0.240180</td>\n",
       "      <td>-1.00550</td>\n",
       "      <td>-0.21139</td>\n",
       "      <td>0.268780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.191800</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.117090</td>\n",
       "      <td>-0.300990</td>\n",
       "      <td>0.144210</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>-0.286770</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>-0.126680</td>\n",
       "      <td>0.091957</td>\n",
       "      <td>-0.319120</td>\n",
       "      <td>-0.385520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428840</td>\n",
       "      <td>0.822160</td>\n",
       "      <td>0.119740</td>\n",
       "      <td>0.28584</td>\n",
       "      <td>0.852120</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.935510</td>\n",
       "      <td>0.84572</td>\n",
       "      <td>0.380180</td>\n",
       "      <td>0.645910</td>\n",
       "      <td>0.422640</td>\n",
       "      <td>0.093864</td>\n",
       "      <td>0.63718</td>\n",
       "      <td>0.93427</td>\n",
       "      <td>-0.083561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.378460</td>\n",
       "      <td>-0.360490</td>\n",
       "      <td>-0.183170</td>\n",
       "      <td>0.123020</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>-0.166920</td>\n",
       "      <td>-0.145840</td>\n",
       "      <td>-0.169000</td>\n",
       "      <td>-0.109340</td>\n",
       "      <td>-0.226630</td>\n",
       "      <td>-0.263040</td>\n",
       "      <td>-0.438560</td>\n",
       "      <td>0.386320</td>\n",
       "      <td>0.235390</td>\n",
       "      <td>0.243240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078753</td>\n",
       "      <td>-0.591150</td>\n",
       "      <td>0.290980</td>\n",
       "      <td>-0.18967</td>\n",
       "      <td>-0.973490</td>\n",
       "      <td>0.13764</td>\n",
       "      <td>-0.099674</td>\n",
       "      <td>-0.78417</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>-0.080984</td>\n",
       "      <td>-0.113330</td>\n",
       "      <td>-0.165450</td>\n",
       "      <td>-0.13914</td>\n",
       "      <td>-0.93286</td>\n",
       "      <td>0.485320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.065890</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>0.132300</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.250450</td>\n",
       "      <td>-0.094085</td>\n",
       "      <td>0.281880</td>\n",
       "      <td>0.265010</td>\n",
       "      <td>-0.379480</td>\n",
       "      <td>-0.050870</td>\n",
       "      <td>-0.006017</td>\n",
       "      <td>0.387650</td>\n",
       "      <td>0.117360</td>\n",
       "      <td>-0.071450</td>\n",
       "      <td>-0.175780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390320</td>\n",
       "      <td>0.476410</td>\n",
       "      <td>-0.266560</td>\n",
       "      <td>0.16413</td>\n",
       "      <td>0.932820</td>\n",
       "      <td>-0.19104</td>\n",
       "      <td>-0.668920</td>\n",
       "      <td>0.20055</td>\n",
       "      <td>0.060713</td>\n",
       "      <td>0.073495</td>\n",
       "      <td>0.161250</td>\n",
       "      <td>-0.345930</td>\n",
       "      <td>-0.16472</td>\n",
       "      <td>-0.51479</td>\n",
       "      <td>-0.731300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2196017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           ,         .       the       and        to        of         a  \\\n",
       "1   -0.082752  0.012001  0.272040 -0.185670  0.319240  0.060216  0.043798   \n",
       "2    0.672040  0.207510 -0.062030  0.066008  0.063160  0.217990  0.024779   \n",
       "3   -0.149870 -0.125780 -0.188400 -0.252090 -0.278580 -0.042490 -0.209370   \n",
       "4   -0.064983 -0.593250  0.023225 -0.117250  0.261200 -0.386180  0.497450   \n",
       "5    0.056491  0.125250 -0.018158  0.265130  0.079248 -0.153880  0.360190   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "296  0.053380  0.063500 -0.018168 -0.039709 -0.258100  0.329200  0.080421   \n",
       "297 -0.050821  0.140190  0.114070  0.324980 -0.044629 -0.175970 -0.061246   \n",
       "298 -0.191800  0.138710  0.130150 -0.023452  0.082745  0.117090 -0.300990   \n",
       "299 -0.378460 -0.360490 -0.183170  0.123020  0.097801 -0.166920 -0.145840   \n",
       "300 -0.065890 -0.035000  0.132300  0.331200  0.250450 -0.094085  0.281880   \n",
       "\n",
       "0          in         \"         :        is       for         I         )  \\\n",
       "1    0.089187 -0.075242  0.008746 -0.084961 -0.172240  0.194100 -0.271420   \n",
       "2    0.257920  0.573370  0.332140  0.502000  0.182340  0.226030  0.047374   \n",
       "3    0.262820 -0.319080 -0.291750  0.002382 -0.278470 -0.437640 -0.172780   \n",
       "4   -0.029365 -0.184840 -0.151190 -0.167550 -0.084666 -0.113870 -0.029084   \n",
       "5    0.471870  0.888670 -0.418420  0.307210  0.254420 -0.072725 -0.219100   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "296  0.193680 -0.212800  0.700590  0.275500 -0.122380 -0.036109  0.066062   \n",
       "297 -0.325460 -0.226150 -0.213710 -0.067180 -0.081083  0.112210 -0.241770   \n",
       "298  0.144210  0.328000 -0.286770 -0.215110 -0.126680  0.091957 -0.319120   \n",
       "299 -0.169000 -0.109340 -0.226630 -0.263040 -0.438560  0.386320  0.235390   \n",
       "300  0.265010 -0.379480 -0.050870 -0.006017  0.387650  0.117360 -0.071450   \n",
       "\n",
       "0           (  ...  what-might-have-been      wiid  windowsTransgender  \\\n",
       "1   -0.180240  ...              0.562950  0.385100           -0.102350   \n",
       "2    0.008411  ...             -0.293780 -0.315230           -0.043862   \n",
       "3   -0.304630  ...              1.279200 -0.103690            0.193270   \n",
       "4    0.209970  ...             -0.070849 -0.110770           -0.225560   \n",
       "5    0.085153  ...             -0.487520  0.172950           -0.148480   \n",
       "..        ...  ...                   ...       ...                 ...   \n",
       "296  0.539500  ...             -0.080746  0.092665           -0.223050   \n",
       "297 -0.235960  ...             -0.571630 -0.087504            0.161510   \n",
       "298 -0.385520  ...              0.428840  0.822160            0.119740   \n",
       "299  0.243240  ...             -0.078753 -0.591150            0.290980   \n",
       "300 -0.175780  ...             -0.390320  0.476410           -0.266560   \n",
       "\n",
       "0    woombie  wordsforyoungmen  work.Like  working.So    wried     wwent  \\\n",
       "1    0.65711         -0.378200   -0.23822    0.754650  0.54698  0.921790   \n",
       "2   -1.06710         -1.154600   -0.65700   -0.292360 -0.50515 -0.344320   \n",
       "3   -0.27787          0.387420   -0.18234   -0.211210  0.56164 -0.508880   \n",
       "4    0.48507          1.288100   -0.27082   -0.105820 -0.29412 -0.000386   \n",
       "5   -0.51166         -0.802670    0.37388   -0.295270 -0.35497 -0.151450   \n",
       "..       ...               ...        ...         ...      ...       ...   \n",
       "296 -0.43677          0.503820    0.28653   -0.484500 -0.21834 -0.406440   \n",
       "297 -0.43438          0.067534   -0.83764   -0.343440  0.44104  0.119900   \n",
       "298  0.28584          0.852120    0.35327    0.935510  0.84572  0.380180   \n",
       "299 -0.18967         -0.973490    0.13764   -0.099674 -0.78417  0.345800   \n",
       "300  0.16413          0.932820   -0.19104   -0.668920  0.20055  0.060713   \n",
       "\n",
       "0     xalisae  xtremecaffeine  yildirim     z/28   zipout  zulchzulu  \n",
       "1    0.337540        0.073032  0.222760  0.73440  0.21215  -0.079690  \n",
       "2   -0.131110       -1.029400 -0.296390 -0.33641 -0.99456  -0.229050  \n",
       "3    0.155950       -0.015436  0.694120  0.26918  1.17820   0.803660  \n",
       "4   -1.124400        0.726150  0.193620  0.41843  2.07210  -0.788650  \n",
       "5    0.100460       -0.992460 -0.312760 -0.18900 -0.44271  -0.405670  \n",
       "..        ...             ...       ...      ...      ...        ...  \n",
       "296 -0.094080        0.127380 -0.413980 -0.48432 -0.41382  -0.205220  \n",
       "297 -0.361960        0.129570  0.240180 -1.00550 -0.21139   0.268780  \n",
       "298  0.645910        0.422640  0.093864  0.63718  0.93427  -0.083561  \n",
       "299 -0.080984       -0.113330 -0.165450 -0.13914 -0.93286   0.485320  \n",
       "300  0.073495        0.161250 -0.345930 -0.16472 -0.51479  -0.731300  \n",
       "\n",
       "[300 rows x 2196017 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glove = pd.read_csv(path, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "df_glove.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b877076",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = { key: val.values for key, val in df_glove.T.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d150142",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.7310e-01,  2.0663e-01,  1.6543e-02, -3.1026e-01,  1.9719e-02,\n",
       "        2.7791e-01,  1.2283e-01, -2.6328e-01,  1.2522e-01,  3.1894e+00,\n",
       "       -1.6291e-01, -8.8759e-02,  3.3067e-03, -2.9483e-03, -3.4398e-01,\n",
       "        1.2779e-01, -9.4536e-02,  4.3467e-01,  4.9742e-01,  2.5068e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['man'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be33d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22418612, -0.28881808,  0.13854355,  0.00365397, -0.12870769,\n",
       "        0.1024395 ,  0.06162703,  0.07317769, -0.06135387, -1.34764119,\n",
       "        0.42038748, -0.0635958 , -0.09683355,  0.18086288,  0.23704431,\n",
       "        0.01412683,  0.1700973 , -1.14917018,  0.31498588,  0.06622261])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_word = df_glove.mean().values\n",
    "unknown_word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c9458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.082752</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>-0.14987</td>\n",
       "      <td>-0.064983</td>\n",
       "      <td>0.056491</td>\n",
       "      <td>0.402280</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-0.331100</td>\n",
       "      <td>-0.306910</td>\n",
       "      <td>2.0817</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>0.30265</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>-0.58190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>0.061068</td>\n",
       "      <td>-0.466200</td>\n",
       "      <td>0.400540</td>\n",
       "      <td>-0.190990</td>\n",
       "      <td>-0.14331</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>-0.18643</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>-0.355980</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>-0.050821</td>\n",
       "      <td>-0.191800</td>\n",
       "      <td>-0.378460</td>\n",
       "      <td>-0.06589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.207510</td>\n",
       "      <td>-0.12578</td>\n",
       "      <td>-0.593250</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.159750</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>-0.331570</td>\n",
       "      <td>-0.136940</td>\n",
       "      <td>1.7893</td>\n",
       "      <td>-0.470940</td>\n",
       "      <td>0.704340</td>\n",
       "      <td>0.26673</td>\n",
       "      <td>-0.089961</td>\n",
       "      <td>-0.18168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021307</td>\n",
       "      <td>-0.107780</td>\n",
       "      <td>-0.228100</td>\n",
       "      <td>0.508030</td>\n",
       "      <td>0.115670</td>\n",
       "      <td>0.16165</td>\n",
       "      <td>-0.066737</td>\n",
       "      <td>-0.29556</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.281350</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.140190</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>-0.360490</td>\n",
       "      <td>-0.03500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.272040</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>-0.18840</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>-0.138770</td>\n",
       "      <td>0.177080</td>\n",
       "      <td>0.177090</td>\n",
       "      <td>2.5882</td>\n",
       "      <td>-0.351790</td>\n",
       "      <td>-0.173120</td>\n",
       "      <td>0.43285</td>\n",
       "      <td>-0.107080</td>\n",
       "      <td>0.15006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301930</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>-0.043102</td>\n",
       "      <td>0.350250</td>\n",
       "      <td>-0.196810</td>\n",
       "      <td>-0.42810</td>\n",
       "      <td>0.168990</td>\n",
       "      <td>0.22511</td>\n",
       "      <td>-0.285570</td>\n",
       "      <td>-0.102800</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>0.114070</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>-0.183170</td>\n",
       "      <td>0.13230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.185670</td>\n",
       "      <td>0.066008</td>\n",
       "      <td>-0.25209</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>0.122910</td>\n",
       "      <td>-0.093979</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>2.4926</td>\n",
       "      <td>-0.017916</td>\n",
       "      <td>-0.071218</td>\n",
       "      <td>-0.24782</td>\n",
       "      <td>-0.262370</td>\n",
       "      <td>-0.22460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>0.477960</td>\n",
       "      <td>0.090912</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>-0.368820</td>\n",
       "      <td>-0.59396</td>\n",
       "      <td>-0.097729</td>\n",
       "      <td>0.20072</td>\n",
       "      <td>0.170550</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>-0.039709</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.123020</td>\n",
       "      <td>0.33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.319240</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>-0.27858</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>-0.214620</td>\n",
       "      <td>-0.104950</td>\n",
       "      <td>0.154950</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>2.4834</td>\n",
       "      <td>-0.509040</td>\n",
       "      <td>0.087490</td>\n",
       "      <td>0.21426</td>\n",
       "      <td>0.221510</td>\n",
       "      <td>-0.25234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237020</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>-0.100310</td>\n",
       "      <td>0.183590</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>-0.12977</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.18888</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.106450</td>\n",
       "      <td>-0.258100</td>\n",
       "      <td>-0.044629</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.25045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2        3         4         5         6         7    \\\n",
       "0                                                                          \n",
       ",   -0.082752  0.672040 -0.14987 -0.064983  0.056491  0.402280  0.002775   \n",
       ".    0.012001  0.207510 -0.12578 -0.593250  0.125250  0.159750  0.137480   \n",
       "the  0.272040 -0.062030 -0.18840  0.023225 -0.018158  0.006719 -0.138770   \n",
       "and -0.185670  0.066008 -0.25209 -0.117250  0.265130  0.064908  0.122910   \n",
       "to   0.319240  0.063160 -0.27858  0.261200  0.079248 -0.214620 -0.104950   \n",
       "\n",
       "          8         9       10        11        12       13        14   \\\n",
       "0                                                                        \n",
       ",   -0.331100 -0.306910  2.0817  0.031819  0.013643  0.30265  0.007130   \n",
       ".   -0.331570 -0.136940  1.7893 -0.470940  0.704340  0.26673 -0.089961   \n",
       "the  0.177080  0.177090  2.5882 -0.351790 -0.173120  0.43285 -0.107080   \n",
       "and -0.093979  0.024321  2.4926 -0.017916 -0.071218 -0.24782 -0.262370   \n",
       "to   0.154950 -0.033530  2.4834 -0.509040  0.087490  0.21426  0.221510   \n",
       "\n",
       "         15   ...       286       287       288       289       290      291  \\\n",
       "0             ...                                                              \n",
       ",   -0.58190  ...  0.074901  0.061068 -0.466200  0.400540 -0.190990 -0.14331   \n",
       ".   -0.18168  ...  0.021307 -0.107780 -0.228100  0.508030  0.115670  0.16165   \n",
       "the  0.15006  ... -0.301930  0.043579 -0.043102  0.350250 -0.196810 -0.42810   \n",
       "and -0.22460  ... -0.005455  0.477960  0.090912  0.094489 -0.368820 -0.59396   \n",
       "to  -0.25234  ... -0.237020  0.038399 -0.100310  0.183590  0.025178 -0.12977   \n",
       "\n",
       "          292      293       294       295       296       297       298  \\\n",
       "0                                                                          \n",
       ",    0.018267 -0.18643  0.207090 -0.355980  0.053380 -0.050821 -0.191800   \n",
       ".   -0.066737 -0.29556  0.022612 -0.281350  0.063500  0.140190  0.138710   \n",
       "the  0.168990  0.22511 -0.285570 -0.102800 -0.018168  0.114070  0.130150   \n",
       "and -0.097729  0.20072  0.170550 -0.004736 -0.039709  0.324980 -0.023452   \n",
       "to   0.371300  0.18888 -0.004274 -0.106450 -0.258100 -0.044629  0.082745   \n",
       "\n",
       "          299      300  \n",
       "0                       \n",
       ",   -0.378460 -0.06589  \n",
       ".   -0.360490 -0.03500  \n",
       "the -0.183170  0.13230  \n",
       "and  0.123020  0.33120  \n",
       "to   0.097801  0.25045  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glove.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b8d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a vectorize representation for each job title in our dataframe\n",
    "job_titles = df.job_title_cleaned\n",
    "\n",
    "doc_sent_vec = []\n",
    "\n",
    "for sentences in job_titles:\n",
    "    word_vec = []\n",
    "    for word in sentences.split():\n",
    "        if word in glove:\n",
    "            vectors = glove[word]\n",
    "            word_vec.append(vectors)\n",
    "        else:\n",
    "            word_vec.append(unknown_word)\n",
    "    word_vec_mean = sum(word_vec) / len(word_vec) # returning a mean for each job title\n",
    "    doc_sent_vec.append(word_vec_mean) # returning a list for all job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0ff57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717d557",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sent_vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd481b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a vectorize representation for each query\n",
    "def q_sent_vec(query):\n",
    "    q_sent_vec = []\n",
    "    q_word_vec = []\n",
    "    \n",
    "    for word in query.split():\n",
    "        if word in glove:\n",
    "            vectors = glove[word]\n",
    "            q_word_vec.append(vectors)\n",
    "        else:\n",
    "            q_word_vec.append(unknown_word)\n",
    "        q_word_vec_mean = sum(q_word_vec) / len(q_word_vec)\n",
    "    q_sent_vec.append(q_word_vec_mean)\n",
    "        \n",
    "    return q_sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd96b33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'native english speaking'\n",
    "len(q_sent_vec(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5322d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sent_vec(query)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6b567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29654333,  0.12640833, -0.49922333,  0.22307667,  0.4358    ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sent_vec(query)[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e1db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10656   ,  0.06428367,  0.10134093, -0.19890667,  0.51552   ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'student indiana university'\n",
    "q_sent_vec(query)[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_query_similarity(doc_sent_vec, query):\n",
    "    \"\"\"\n",
    "    query_glove: processing the query\n",
    "    doc_sent_vec: glove embedding for all docs\n",
    "    query: query doc\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "\n",
    "    \"\"\"\n",
    "    query_glove = q_sent_vec(query)\n",
    "    \n",
    "    cos_sim_glove = cosine_similarity(query_glove, doc_sent_vec).flatten()\n",
    "    \n",
    "    return cos_sim_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Aspiring human resources'\n",
    "\n",
    "#GloVe similarity\n",
    "cos_sim_glove = get_glove_query_similarity(doc_sent_vec, query = query)\n",
    "df['glove_fit'] = cos_sim_glove\n",
    "\n",
    "# original TFIDF similarity and Word2Vec Similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim\n",
    "\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637981cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "      <th>glove_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "      <td>0.851023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "      <td>0.851023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.632697</td>\n",
       "      <td>0.848638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>aspiring human resources manager  seeking inte...</td>\n",
       "      <td>0.584569</td>\n",
       "      <td>0.508880</td>\n",
       "      <td>0.845360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>human resources professional</td>\n",
       "      <td>0.134220</td>\n",
       "      <td>0.340769</td>\n",
       "      <td>0.836803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.619797</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.825179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>human resources generalist loparex</td>\n",
       "      <td>0.202520</td>\n",
       "      <td>0.196509</td>\n",
       "      <td>0.799749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>human resources specialist luxottica</td>\n",
       "      <td>0.151158</td>\n",
       "      <td>0.189503</td>\n",
       "      <td>0.790386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.654387</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.776370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>0.245337</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>0.628601</td>\n",
       "      <td>0.374733</td>\n",
       "      <td>0.773825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "97               Aspiring Human Resources Professional   \n",
       "3                Aspiring Human Resources Professional   \n",
       "6                  Aspiring Human Resources Specialist   \n",
       "73   Aspiring Human Resources Manager, seeking inte...   \n",
       "74                        Human Resources Professional   \n",
       "28               Seeking Human Resources Opportunities   \n",
       "101              Human Resources Generalist at Loparex   \n",
       "68             Human Resources Specialist at Luxottica   \n",
       "99                    Seeking Human Resources Position   \n",
       "27   Aspiring Human Resources Management student se...   \n",
       "\n",
       "                                location  connection       fit  \\\n",
       "id                                                               \n",
       "97                  Kokomo, Indiana Area          71  0.240319   \n",
       "3    Raleigh-Durham, North Carolina Area          44  0.240319   \n",
       "6             Greater New York City Area           1  0.206629   \n",
       "73                   Houston, Texas Area           7  0.362648   \n",
       "74                   Greater Boston Area          16  0.295223   \n",
       "28                     Chicago, Illinois         390  0.675682   \n",
       "101  Raleigh-Durham, North Carolina Area         501  0.170244   \n",
       "68            Greater New York City Area         501  0.164174   \n",
       "99                Las Vegas, Nevada Area          48  0.675682   \n",
       "27                   Houston, Texas Area         501  0.245337   \n",
       "\n",
       "                                     job_title_cleaned   w2v_fit  tfidf_fit  \\\n",
       "id                                                                            \n",
       "97               aspiring human resources professional  0.898174   0.735855   \n",
       "3                aspiring human resources professional  0.898174   0.735855   \n",
       "6                  aspiring human resources specialist  0.873679   0.632697   \n",
       "73   aspiring human resources manager  seeking inte...  0.584569   0.508880   \n",
       "74                        human resources professional  0.134220   0.340769   \n",
       "28               seeking human resources opportunities  0.619797   0.220668   \n",
       "101                 human resources generalist loparex  0.202520   0.196509   \n",
       "68                human resources specialist luxottica  0.151158   0.189503   \n",
       "99                    seeking human resources position  0.654387   0.220668   \n",
       "27   aspiring human resources management student se...  0.628601   0.374733   \n",
       "\n",
       "     glove_fit  \n",
       "id              \n",
       "97    0.851023  \n",
       "3     0.851023  \n",
       "6     0.848638  \n",
       "73    0.845360  \n",
       "74    0.836803  \n",
       "28    0.825179  \n",
       "101   0.799749  \n",
       "68    0.790386  \n",
       "99    0.776370  \n",
       "27    0.773825  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'glove_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11305ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'seeking human resources'\n",
    "\n",
    "#GloVe similarity\n",
    "cos_sim_glove = get_glove_query_similarity(doc_sent_vec, query = query)\n",
    "df['glove_fit'] = cos_sim_glove\n",
    "\n",
    "# original TFIDF similarity and Word2Vec Similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim\n",
    "\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd4ee3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "      <th>glove_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.839381</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>0.970024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.886226</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>0.953714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>aspiring human resources manager  seeking inte...</td>\n",
       "      <td>0.431644</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>0.935586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>human resources professional</td>\n",
       "      <td>0.133104</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>0.903558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Seeking Human  Resources Opportunities. Open t...</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>415</td>\n",
       "      <td>0.381290</td>\n",
       "      <td>seeking human resources opportunities  open tr...</td>\n",
       "      <td>0.639099</td>\n",
       "      <td>0.381290</td>\n",
       "      <td>0.885495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>0.874185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Aspiring Human Resources Manager | Graduating ...</td>\n",
       "      <td>Cape Girardeau, Missouri</td>\n",
       "      <td>103</td>\n",
       "      <td>0.220083</td>\n",
       "      <td>aspiring human resources manager   graduating ...</td>\n",
       "      <td>0.343832</td>\n",
       "      <td>0.220083</td>\n",
       "      <td>0.870053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.864091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.864091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Human Resources Management Major</td>\n",
       "      <td>Milpitas, California</td>\n",
       "      <td>18</td>\n",
       "      <td>0.177288</td>\n",
       "      <td>human resources management major</td>\n",
       "      <td>0.170611</td>\n",
       "      <td>0.177288</td>\n",
       "      <td>0.859179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "28               Seeking Human Resources Opportunities   \n",
       "99                    Seeking Human Resources Position   \n",
       "73   Aspiring Human Resources Manager, seeking inte...   \n",
       "74                        Human Resources Professional   \n",
       "94   Seeking Human  Resources Opportunities. Open t...   \n",
       "6                  Aspiring Human Resources Specialist   \n",
       "100  Aspiring Human Resources Manager | Graduating ...   \n",
       "3                Aspiring Human Resources Professional   \n",
       "97               Aspiring Human Resources Professional   \n",
       "88                    Human Resources Management Major   \n",
       "\n",
       "                                location  connection       fit  \\\n",
       "id                                                               \n",
       "28                     Chicago, Illinois         390  0.675682   \n",
       "99                Las Vegas, Nevada Area          48  0.675682   \n",
       "73                   Houston, Texas Area           7  0.362648   \n",
       "74                   Greater Boston Area          16  0.295223   \n",
       "94           Amerika Birleşik Devletleri         415  0.381290   \n",
       "6             Greater New York City Area           1  0.206629   \n",
       "100             Cape Girardeau, Missouri         103  0.220083   \n",
       "3    Raleigh-Durham, North Carolina Area          44  0.240319   \n",
       "97                  Kokomo, Indiana Area          71  0.240319   \n",
       "88                  Milpitas, California          18  0.177288   \n",
       "\n",
       "                                     job_title_cleaned   w2v_fit  tfidf_fit  \\\n",
       "id                                                                            \n",
       "28               seeking human resources opportunities  0.839381   0.675682   \n",
       "99                    seeking human resources position  0.886226   0.675682   \n",
       "73   aspiring human resources manager  seeking inte...  0.431644   0.362648   \n",
       "74                        human resources professional  0.133104   0.295223   \n",
       "94   seeking human resources opportunities  open tr...  0.639099   0.381290   \n",
       "6                  aspiring human resources specialist  0.645122   0.206629   \n",
       "100  aspiring human resources manager   graduating ...  0.343832   0.220083   \n",
       "3                aspiring human resources professional  0.663209   0.240319   \n",
       "97               aspiring human resources professional  0.663209   0.240319   \n",
       "88                    human resources management major  0.170611   0.177288   \n",
       "\n",
       "     glove_fit  \n",
       "id              \n",
       "28    0.970024  \n",
       "99    0.953714  \n",
       "73    0.935586  \n",
       "74    0.903558  \n",
       "94    0.885495  \n",
       "6     0.874185  \n",
       "100   0.870053  \n",
       "3     0.864091  \n",
       "97    0.864091  \n",
       "88    0.859179  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'glove_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394ed03",
   "metadata": {},
   "source": [
    "# Fasttext \n",
    "FastText is a library developed by Facebook for NLP - known for its training speed and accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\achung\\\\OneDrive - Biological Dynamics, Inc\\\\LX Temp\\\\Apziva\\\\Potential Talent',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\python310.zip',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\DLLs',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\lib',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env',\n",
       " '',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\lib\\\\site-packages',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\lib\\\\site-packages\\\\win32',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'c:\\\\Users\\\\achung\\\\Miniconda3\\\\envs\\\\al_env\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e3376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install wget\n",
    "!pip3.10 install --user wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c741a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastText-0.9.2.zip'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Downloading fastText pre-trained vectors\n",
    "import wget\n",
    "wget.download('https://github.com/facebookresearch/fastText/archive/v0.9.2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting fastText vector file\n",
    "import zipfile as zf\n",
    "files = zf.ZipFile(\"fastText-0.9.2.zip\", 'r')\n",
    "files.extractall()\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677bfdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\achung\\OneDrive - Biological Dynamics, Inc\\LX Temp\\Apziva\\Potential Talent\\fastText-0.9.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f0d08",
   "metadata": {},
   "source": [
    "#### Issues and workarounds with installing fasttext:\n",
    "\n",
    "https://stackoverflow.com/questions/44951456/pip-error-microsoft-visual-c-14-0-is-required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c89bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (24.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 65.8/65.8 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: wheel\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "Successfully installed wheel-0.43.0\n",
      "Requirement already satisfied: setuptools in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (61.2.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Downloading setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "   --------------------------------------- 863.4/863.4 kB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 61.2.0\n",
      "    Uninstalling setuptools-61.2.0:\n",
      "      Successfully uninstalled setuptools-61.2.0\n",
      "Successfully installed setuptools-70.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --install-option\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade wheel\n",
    "# !pip install --upgrade setuptools\n",
    "# !pip install Cython --install-option=\"--no-cython-compile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext-wheel in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from fasttext-wheel) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from fasttext-wheel) (70.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from fasttext-wheel) (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install fasttext\n",
    "# !pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ad6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext as fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea73120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downloading pretrained model trained on Common Crawl and Wikipedia\n",
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English Skip downloading if you've already downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85caf6be",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ft \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcc.en.300.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\fasttext\\FastText.py:436\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(path):\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\fasttext\\FastText.py:94\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mfasttext()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de8326",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fasttext' has no attribute 'get_word_vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_word_vector\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m20\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fasttext' has no attribute 'get_word_vector'"
     ]
    }
   ],
   "source": [
    "ft.get_word_vector('hello')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5968c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'the', '.', 'and', 'to', 'of', 'a', '</s>', 'in', 'is']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_words()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03726c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of fasttext word and vector representaiton\n",
    "ft_words = ft.get_words()\n",
    "ft_vectors = [ft.get_word_vector(word) for word in ft_words]\n",
    "ft_dict = dict(zip(ft_words, ft_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15757619,  0.04378209, -0.00451272,  0.06659314,  0.07703468,\n",
       "        0.00485855,  0.00819822,  0.00652403,  0.009259  ,  0.0353899 ,\n",
       "       -0.02313953, -0.04918071, -0.08326425,  0.01560145,  0.25485662,\n",
       "        0.03454237, -0.01074514, -0.07801886, -0.07080995,  0.07623856],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_dict['hello'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.DataFrame(ft_dict.items(), columns = ['ft_words', 'ft_vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147309e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_words</th>\n",
       "      <th>ft_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>[0.12502378, -0.10790165, 0.02450176, -0.25286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>[-0.051744193, 0.073963955, -0.01305688, 0.044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[0.03423236, -0.08014102, 0.116187684, -0.3968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>[0.008239111, -0.089902766, 0.026525287, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>[0.0046811374, 0.02812425, -0.029631453, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>[-7.303824e-05, -0.18774074, -0.07105116, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.08764305, -0.49590126, -0.04985499, -0.0936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>[0.073061086, -0.24302974, -0.035331346, -0.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>[-0.014047037, -0.25217462, 0.07150193, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>[-0.09776052, -0.20827363, -0.10372388, -0.016...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ft_words                                         ft_vectors\n",
       "0        ,  [0.12502378, -0.10790165, 0.02450176, -0.25286...\n",
       "1      the  [-0.051744193, 0.073963955, -0.01305688, 0.044...\n",
       "2        .  [0.03423236, -0.08014102, 0.116187684, -0.3968...\n",
       "3      and  [0.008239111, -0.089902766, 0.026525287, -0.00...\n",
       "4       to  [0.0046811374, 0.02812425, -0.029631453, -0.01...\n",
       "5       of  [-7.303824e-05, -0.18774074, -0.07105116, -0.4...\n",
       "6        a  [0.08764305, -0.49590126, -0.04985499, -0.0936...\n",
       "7     </s>  [0.073061086, -0.24302974, -0.035331346, -0.36...\n",
       "8       in  [-0.014047037, -0.25217462, 0.07150193, -0.024...\n",
       "9       is  [-0.09776052, -0.20827363, -0.10372388, -0.016..."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be45db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May not need to do this for fasttext\n",
    "oov_word = np.zeros((300,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fasttext vectorize representation for each job title in our dataframe\n",
    "job_titles = df.job_title_cleaned\n",
    "\n",
    "doc_sent_vec_ft = []\n",
    "\n",
    "for sentences in job_titles:\n",
    "    word_vec_ft = []\n",
    "    for word in sentences.split():\n",
    "        if word in ft_dict:\n",
    "            vectors = ft_dict[word]\n",
    "            word_vec_ft.append(vectors)\n",
    "        else:\n",
    "            word_vec_ft.append(oov_word)\n",
    "    word_vec_mean_ft = sum(word_vec_ft) / len(word_vec_ft) # returning a mean for each job title\n",
    "    doc_sent_vec_ft.append(word_vec_mean_ft) # returning a list for all job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fasttext vectorize representation for each query\n",
    "def q_sent_vec_ft(query):\n",
    "    q_sent_vec_ft = []\n",
    "    q_word_vec_ft = []\n",
    "    \n",
    "    for word in query.split():\n",
    "        if word in ft_dict:\n",
    "            vectors = ft_dict[word]\n",
    "            q_word_vec_ft.append(vectors)\n",
    "        else:\n",
    "            q_word_vec_ft.append(oov_word)\n",
    "        q_word_vec_mean_ft = sum(q_word_vec_ft) / len(q_word_vec_ft)\n",
    "    q_sent_vec_ft.append(q_word_vec_mean_ft)\n",
    "        \n",
    "    return q_sent_vec_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_query_similarity(doc_sent_vec_ft, query):\n",
    "    \"\"\"\n",
    "    query_fasttext: processing the query\n",
    "    doc_sent_vec: glove embedding for all docs\n",
    "    query: query doc\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "\n",
    "    \"\"\"\n",
    "    query_fasttext = q_sent_vec_ft(query)\n",
    "    \n",
    "    cos_sim_fasttext = cosine_similarity(query_fasttext, doc_sent_vec_ft).flatten()\n",
    "    \n",
    "    return cos_sim_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fasttext = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Aspiring human resources'\n",
    "\n",
    "#Fasttext similarity\n",
    "cos_sim_fasttext = get_fasttext_query_similarity(doc_sent_vec_ft, query = query)\n",
    "df['fasttext_fit'] = cos_sim_fasttext\n",
    "\n",
    "# original TFIDF similarity and Word2Vec Similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim\n",
    "\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v\n",
    "\n",
    "cos_sim_glove = get_glove_query_similarity(doc_sent_vec, query = query)\n",
    "df['glove_fit'] = cos_sim_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006c31a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "      <th>glove_fit</th>\n",
       "      <th>fasttext_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "      <td>0.851023</td>\n",
       "      <td>0.905892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.735855</td>\n",
       "      <td>0.851023</td>\n",
       "      <td>0.905892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.632697</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.888034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>human resources professional</td>\n",
       "      <td>0.134220</td>\n",
       "      <td>0.340769</td>\n",
       "      <td>0.836803</td>\n",
       "      <td>0.877046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>aspiring human resources manager  seeking inte...</td>\n",
       "      <td>0.584569</td>\n",
       "      <td>0.508880</td>\n",
       "      <td>0.845360</td>\n",
       "      <td>0.860426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>human resources generalist loparex</td>\n",
       "      <td>0.202520</td>\n",
       "      <td>0.196509</td>\n",
       "      <td>0.799749</td>\n",
       "      <td>0.841223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>human resources specialist luxottica</td>\n",
       "      <td>0.151158</td>\n",
       "      <td>0.189503</td>\n",
       "      <td>0.790386</td>\n",
       "      <td>0.834961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.619797</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.825179</td>\n",
       "      <td>0.815429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.654387</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.776370</td>\n",
       "      <td>0.783930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>0.628601</td>\n",
       "      <td>0.374733</td>\n",
       "      <td>0.773825</td>\n",
       "      <td>0.776401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "97               Aspiring Human Resources Professional   \n",
       "3                Aspiring Human Resources Professional   \n",
       "6                  Aspiring Human Resources Specialist   \n",
       "74                        Human Resources Professional   \n",
       "73   Aspiring Human Resources Manager, seeking inte...   \n",
       "101              Human Resources Generalist at Loparex   \n",
       "68             Human Resources Specialist at Luxottica   \n",
       "28               Seeking Human Resources Opportunities   \n",
       "99                    Seeking Human Resources Position   \n",
       "27   Aspiring Human Resources Management student se...   \n",
       "\n",
       "                                location  connection  \\\n",
       "id                                                     \n",
       "97                  Kokomo, Indiana Area          71   \n",
       "3    Raleigh-Durham, North Carolina Area          44   \n",
       "6             Greater New York City Area           1   \n",
       "74                   Greater Boston Area          16   \n",
       "73                   Houston, Texas Area           7   \n",
       "101  Raleigh-Durham, North Carolina Area         501   \n",
       "68            Greater New York City Area         501   \n",
       "28                     Chicago, Illinois         390   \n",
       "99                Las Vegas, Nevada Area          48   \n",
       "27                   Houston, Texas Area         501   \n",
       "\n",
       "                                     job_title_cleaned   w2v_fit  tfidf_fit  \\\n",
       "id                                                                            \n",
       "97               aspiring human resources professional  0.898174   0.735855   \n",
       "3                aspiring human resources professional  0.898174   0.735855   \n",
       "6                  aspiring human resources specialist  0.873679   0.632697   \n",
       "74                        human resources professional  0.134220   0.340769   \n",
       "73   aspiring human resources manager  seeking inte...  0.584569   0.508880   \n",
       "101                 human resources generalist loparex  0.202520   0.196509   \n",
       "68                human resources specialist luxottica  0.151158   0.189503   \n",
       "28               seeking human resources opportunities  0.619797   0.220668   \n",
       "99                    seeking human resources position  0.654387   0.220668   \n",
       "27   aspiring human resources management student se...  0.628601   0.374733   \n",
       "\n",
       "     glove_fit  fasttext_fit  \n",
       "id                            \n",
       "97    0.851023      0.905892  \n",
       "3     0.851023      0.905892  \n",
       "6     0.848638      0.888034  \n",
       "74    0.836803      0.877046  \n",
       "73    0.845360      0.860426  \n",
       "101   0.799749      0.841223  \n",
       "68    0.790386      0.834961  \n",
       "28    0.825179      0.815429  \n",
       "99    0.776370      0.783930  \n",
       "27    0.773825      0.776401  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'fasttext_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'seeking human resources'\n",
    "\n",
    "#Fasttext similarity\n",
    "cos_sim_fasttext = get_fasttext_query_similarity(doc_sent_vec_ft, query = query)\n",
    "df['fasttext_fit'] = cos_sim_fasttext\n",
    "\n",
    "# original TFIDF similarity and Word2Vec Similarity for comparison\n",
    "cos_sim = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "df['tfidf_fit'] = cos_sim\n",
    "\n",
    "cos_sim_w2v = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "df['w2v_fit'] = cos_sim_w2v\n",
    "\n",
    "cos_sim_glove = get_glove_query_similarity(doc_sent_vec, query = query)\n",
    "df['glove_fit'] = cos_sim_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579beff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>w2v_fit</th>\n",
       "      <th>tfidf_fit</th>\n",
       "      <th>glove_fit</th>\n",
       "      <th>fasttext_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>0.839381</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.981158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>0.886226</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>0.953714</td>\n",
       "      <td>0.956870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>aspiring human resources manager  seeking inte...</td>\n",
       "      <td>0.431644</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.924971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Human Resources Professional</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "      <td>16</td>\n",
       "      <td>human resources professional</td>\n",
       "      <td>0.133104</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>0.903558</td>\n",
       "      <td>0.905220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>501</td>\n",
       "      <td>human resources specialist luxottica</td>\n",
       "      <td>0.150797</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>0.852014</td>\n",
       "      <td>0.893244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>501</td>\n",
       "      <td>human resources generalist loparex</td>\n",
       "      <td>0.204287</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.805987</td>\n",
       "      <td>0.876087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>0.874185</td>\n",
       "      <td>0.871857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.864091</td>\n",
       "      <td>0.865438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.864091</td>\n",
       "      <td>0.865438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>501</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>0.464157</td>\n",
       "      <td>0.245337</td>\n",
       "      <td>0.856657</td>\n",
       "      <td>0.830511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "id                                                       \n",
       "28               Seeking Human Resources Opportunities   \n",
       "99                    Seeking Human Resources Position   \n",
       "73   Aspiring Human Resources Manager, seeking inte...   \n",
       "74                        Human Resources Professional   \n",
       "68             Human Resources Specialist at Luxottica   \n",
       "101              Human Resources Generalist at Loparex   \n",
       "6                  Aspiring Human Resources Specialist   \n",
       "3                Aspiring Human Resources Professional   \n",
       "97               Aspiring Human Resources Professional   \n",
       "27   Aspiring Human Resources Management student se...   \n",
       "\n",
       "                                location  connection  \\\n",
       "id                                                     \n",
       "28                     Chicago, Illinois         390   \n",
       "99                Las Vegas, Nevada Area          48   \n",
       "73                   Houston, Texas Area           7   \n",
       "74                   Greater Boston Area          16   \n",
       "68            Greater New York City Area         501   \n",
       "101  Raleigh-Durham, North Carolina Area         501   \n",
       "6             Greater New York City Area           1   \n",
       "3    Raleigh-Durham, North Carolina Area          44   \n",
       "97                  Kokomo, Indiana Area          71   \n",
       "27                   Houston, Texas Area         501   \n",
       "\n",
       "                                     job_title_cleaned   w2v_fit  tfidf_fit  \\\n",
       "id                                                                            \n",
       "28               seeking human resources opportunities  0.839381   0.675682   \n",
       "99                    seeking human resources position  0.886226   0.675682   \n",
       "73   aspiring human resources manager  seeking inte...  0.431644   0.362648   \n",
       "74                        human resources professional  0.133104   0.295223   \n",
       "68                human resources specialist luxottica  0.150797   0.164174   \n",
       "101                 human resources generalist loparex  0.204287   0.170244   \n",
       "6                  aspiring human resources specialist  0.645122   0.206629   \n",
       "3                aspiring human resources professional  0.663209   0.240319   \n",
       "97               aspiring human resources professional  0.663209   0.240319   \n",
       "27   aspiring human resources management student se...  0.464157   0.245337   \n",
       "\n",
       "     glove_fit  fasttext_fit  \n",
       "id                            \n",
       "28    0.970024      0.981158  \n",
       "99    0.953714      0.956870  \n",
       "73    0.935586      0.924971  \n",
       "74    0.903558      0.905220  \n",
       "68    0.852014      0.893244  \n",
       "101   0.805987      0.876087  \n",
       "6     0.874185      0.871857  \n",
       "3     0.864091      0.865438  \n",
       "97    0.864091      0.865438  \n",
       "27    0.856657      0.830511  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates(n = 10, by = 'fasttext_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5614b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4273],\n",
      "        [0.2248],\n",
      "        [0.7727],\n",
      "        [0.3772],\n",
      "        [0.2317],\n",
      "        [0.7807],\n",
      "        [0.6295],\n",
      "        [0.4721],\n",
      "        [0.8080],\n",
      "        [0.2799],\n",
      "        [0.3458],\n",
      "        [0.5949],\n",
      "        [0.6228],\n",
      "        [0.8992],\n",
      "        [0.5516],\n",
      "        [0.7287],\n",
      "        [0.6107],\n",
      "        [0.5813],\n",
      "        [0.6308],\n",
      "        [0.6361],\n",
      "        [0.5291],\n",
      "        [0.6247],\n",
      "        [0.7271],\n",
      "        [0.4753],\n",
      "        [0.6622],\n",
      "        [0.5668],\n",
      "        [0.6536],\n",
      "        [0.5160],\n",
      "        [0.3302],\n",
      "        [0.4746],\n",
      "        [0.6206],\n",
      "        [0.4798],\n",
      "        [0.5269],\n",
      "        [0.1083],\n",
      "        [0.3251],\n",
      "        [0.1982],\n",
      "        [0.6019],\n",
      "        [0.5574],\n",
      "        [0.3122],\n",
      "        [0.2498],\n",
      "        [0.4267],\n",
      "        [0.2027],\n",
      "        [0.6791],\n",
      "        [0.2658],\n",
      "        [0.2725],\n",
      "        [0.7727],\n",
      "        [0.1248],\n",
      "        [0.9041],\n",
      "        [0.6760],\n",
      "        [0.6292],\n",
      "        [0.1461],\n",
      "        [0.1456],\n",
      "        [0.2503]])\n"
     ]
    }
   ],
   "source": [
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7cb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted values:\n",
      " tensor([[0.4273],\n",
      "        [0.2248],\n",
      "        [0.7727],\n",
      "        [0.3772],\n",
      "        [0.2317],\n",
      "        [0.7807],\n",
      "        [0.6295],\n",
      "        [0.4721],\n",
      "        [0.8080],\n",
      "        [0.2799],\n",
      "        [0.3458],\n",
      "        [0.5949],\n",
      "        [0.6228],\n",
      "        [0.8992],\n",
      "        [0.5516],\n",
      "        [0.7287],\n",
      "        [0.6107],\n",
      "        [0.5813],\n",
      "        [0.6308],\n",
      "        [0.6361],\n",
      "        [0.5291],\n",
      "        [0.6247],\n",
      "        [0.7271],\n",
      "        [0.4753],\n",
      "        [0.6622],\n",
      "        [0.5668],\n",
      "        [0.6536],\n",
      "        [0.5160],\n",
      "        [0.3302],\n",
      "        [0.4746],\n",
      "        [0.6206],\n",
      "        [0.4798],\n",
      "        [0.5269],\n",
      "        [0.1083],\n",
      "        [0.3251],\n",
      "        [0.1982],\n",
      "        [0.6019],\n",
      "        [0.5574],\n",
      "        [0.3122],\n",
      "        [0.2498],\n",
      "        [0.4267],\n",
      "        [0.2027],\n",
      "        [0.6791],\n",
      "        [0.2658],\n",
      "        [0.2725],\n",
      "        [0.7727],\n",
      "        [0.1248],\n",
      "        [0.9041],\n",
      "        [0.6760],\n",
      "        [0.6292],\n",
      "        [0.1461],\n",
      "        [0.1456],\n",
      "        [0.2503]])\n",
      "Indices:\n",
      " tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# printing values of sorted tensor \n",
    "print(\"Sorted values:\\n\", values) \n",
    "  \n",
    "# printing indices of sorted value \n",
    "print(\"Indices:\\n\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61128e1e",
   "metadata": {},
   "source": [
    "# BERT - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f199f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 43.8/43.8 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (1.13.1+cu117)\n",
      "Requirement already satisfied: numpy in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.8.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.10.31)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.6.15)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 227.1/227.1 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 9.1/9.1 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 287.4/287.4 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.2\n",
      "    Uninstalling transformers-4.27.2:\n",
      "      Successfully uninstalled transformers-4.27.2\n",
      "Successfully installed safetensors-0.4.3 sentence-transformers-3.0.1 tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/sentence-transformers/\n"
     ]
    }
   ],
   "source": [
    "# First install\n",
    "# # !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe9978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = df['job_title_cleaned'].to_list()\n",
    "embeddings = model.encode(titles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_query_similarity(embeddings, query):\n",
    "    \"\"\"\n",
    "    embeddings: bert embedding for all docs\n",
    "    query: query doc\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    similarities = model.similarity(embeddings, query_embedding)\n",
    "    \n",
    "    cos_sim_bert = [x.item() for x in similarities]\n",
    "    \n",
    "    return cos_sim_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'seeking human resources'\n",
    "cos_sim_bert = get_bert_query_similarity(embeddings, query = query)\n",
    "df['bert_fit'] = cos_sim_bert\n",
    "\n",
    "top_candidates(n = 10, by = 'bert_fit', ascending = False, min_con = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input candidates, query term, location, etc\n",
    "query = 'seeking human resources'\n",
    "\n",
    "def cos_sim_various(query):\n",
    "    \n",
    "    #Fasttext similarity\n",
    "    df['fasttext_fit'] = get_fasttext_query_similarity(doc_sent_vec_ft, query = query)\n",
    "\n",
    "    # original TFIDF similarity and Word2Vec Similarity for comparison\n",
    "    df['tfidf_fit'] = get_tf_idf_query_similarity(vectorizer, docs_tfidf, query = query) \n",
    "\n",
    "    df['w2v_fit'] = get_w2v_query_similarity(document_word_embeddings, query = query)\n",
    "\n",
    "    df['glove_fit'] = get_glove_query_similarity(doc_sent_vec, query = query)\n",
    "    \n",
    "    df['bert_fit'] = get_bert_query_similarity(embeddings, query = query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordtoVec  Same thing but with pretrained word embedding average of word\n",
    "# Try to see who I'm connected with \n",
    "skill review surrvey - schedule interview - motivated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df22c85",
   "metadata": {},
   "source": [
    "Process:\n",
    "1. Sentence transformer:\n",
    "    https://sbert.net/\n",
    "    https://www.geeksforgeeks.org/sentence-similarity-using-bert-transformer/\n",
    "\n",
    "\n",
    "2. Gen AI\n",
    "https://stackoverflow.com/questions/75673222/semantic-searching-using-google-flan-t5\n",
    "\n",
    "3. Utilizing LLM via prompting\n",
    "GPT general purpose transformer - closed boxed model through an Open AI API\n",
    "- Focus on instead, take advantage of open source LLM such as LLama 3 model from Meta\n",
    "- Mistral, Llama 2, Grok maybe?\n",
    "\n",
    "Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038d92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781fc720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3c5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670d2b05",
   "metadata": {},
   "source": [
    "# Gen AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ed34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.17.0\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.6/536.6 kB 6.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (1.23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (3.8.2)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "     -------------------------------------- 166.4/166.4 kB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (4.64.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl (370 kB)\n",
      "     ------------------------------------- 370.7/370.7 kB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (21.3)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "     ---------------------------------------- 116.3/116.3 kB ? eta 0:00:00\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (2.28.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 134.8/134.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (1.4.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from datasets==2.17.0) (14.0.1)\n",
      "Collecting huggingface-hub>=0.19.4\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "     ------------------------------------- 401.7/401.7 kB 24.5 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from packaging->datasets==2.17.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2022.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.17.0) (0.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from pandas->datasets==2.17.0) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from pandas->datasets==2.17.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.17.0) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.11.1\n",
      "    Uninstalling huggingface-hub-0.11.1:\n",
      "      Successfully uninstalled huggingface-hub-0.11.1\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.17.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2023.10.0 huggingface-hub-0.23.2 multidict-6.0.5 multiprocess-0.70.16 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in c:\\users\\achung\\miniconda3\\envs\\al_env\\lib\\site-packages (22.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 10.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.1.2\n",
      "    Uninstalling pip-22.1.2:\n",
      "      Successfully uninstalled pip-22.1.2\n",
      "Successfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets==2.17.0\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec48fb7c83c4c2aa41dc1408d07089f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\achung\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee442a2ff5d43cbb6b6ff3e6d71700b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a191c93ed09433f8564d5c9729e0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c3d3cd3d81414ba327f5c887799ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a22b2df8e949eaadd6191baae652f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f38a7e973c4a178b850486d0930bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae2496961ae4559ae9e05a906deaf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf5822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODED SENTENCE:\n",
      "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n",
      "\n",
      "DECODED SENTENCE:\n",
      "What time is it, Tom?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it, Tom?\"\n",
    "\n",
    "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"][0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "print('ENCODED SENTENCE:')\n",
    "print(sentence_encoded[\"input_ids\"][0])\n",
    "print('\\nDECODED SENTENCE:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac84e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoded[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf20ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenized input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a8a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0667fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab2baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed514b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d0085",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.mean(sentence_encoded[\"input_ids\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639fd28",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (axis=NoneType, dtype=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [105]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\achung\\Miniconda3\\envs\\al_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3428\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   3429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3433\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (axis=NoneType, dtype=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46907124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorize representation for each job title in our dataframe\n",
    "job_titles = df.job_title_cleaned\n",
    "\n",
    "doc_sent_vec = []\n",
    "\n",
    "for sentences in job_titles:\n",
    "    sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    sentence_encoded = sum(word_vec) / len(word_vec) # returning a mean for each job title\n",
    "    doc_sent_vec.append(word_vec_mean) # returning a list for all job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_indices = [40, 200]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print('INPUT DIALOGUE:')\n",
    "    print(dataset['test'][index]['dialogue'])\n",
    "    print(dash_line)\n",
    "    print('BASELINE HUMAN SUMMARY:')\n",
    "    print(dataset['test'][index]['summary'])\n",
    "    print(dash_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4840fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b971a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
